{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9462ce-5c07-4155-a8fd-1eb09b22a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate, interpolate\n",
    "from scipy import optimize\n",
    "from torch.autograd import grad\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.integrate import solve_ivp, odeint\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3aee7ec-798b-4a29-bc78-1762a0bf764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN_sys(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PINN_sys, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, output_size), nn.Tanh()\n",
    "        )\n",
    "        self.params = nn.Parameter(torch.rand(3))  # Learnable parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Training function\n",
    "def train_pinn_sys(model, \n",
    "                   t_train, \n",
    "                   G1_data,\n",
    "                   G2_data,\n",
    "                   P_data,\n",
    "                   D_data,\n",
    "                   zero_init,\n",
    "                   known_param,\n",
    "                   num_epochs, \n",
    "                   learning_rate\n",
    "                   ):\n",
    "    \n",
    "    # Define the loss function (MSE for the PINN)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Define the learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=50, factor=0.5, verbose=True)\n",
    "    \n",
    "    # write the loss and params to a list\n",
    "    epoch_list = []\n",
    "    loss_list = []\n",
    "    fg_list = []\n",
    "    fm_list = []\n",
    "    fp_list = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Convert to PyTorch tensors\n",
    "        t_train = torch.FloatTensor(t_train.reshape(-1, 1))\n",
    "        G1_tensor = torch.FloatTensor(G1_data.reshape(-1, 1))\n",
    "        G2_tensor = torch.FloatTensor(G2_data.reshape(-1, 1))\n",
    "        P_tensor = torch.FloatTensor(P_data.reshape(-1, 1))\n",
    "        D_tensor = torch.FloatTensor(D_data.reshape(-1, 1))\n",
    "        zero_init = torch.FloatTensor(zero_init.reshape(-1, 1))\n",
    "        known_param = torch.FloatTensor(known_param.reshape(-1, 1))\n",
    "        \n",
    "        t_train.requires_grad_()\n",
    "\n",
    "        # Forward pass\n",
    "        NN = model(t_train)\n",
    "        G1, G2, P, D = torch.split(NN, 1, dim=1)\n",
    "        \n",
    "        G1_ones = torch.ones_like(G1)\n",
    "        G2_ones = torch.ones_like(G2)\n",
    "        P_ones = torch.ones_like(P)\n",
    "        D_ones = torch.ones_like(D)\n",
    "\n",
    "        # Compute the gradients of the variables\n",
    "        G1_t = grad(G1, t_train, G1_ones, create_graph=True)[0]\n",
    "        G2_t = grad(G2, t_train, G2_ones, create_graph=True)[0]\n",
    "        P_t = grad(P, t_train, P_ones, create_graph=True)[0]\n",
    "        D_t = grad(D, t_train, D_ones, create_graph=True)[0]\n",
    "        \n",
    "        # ensure the model parameters are positive\n",
    "        param_reg = torch.abs(model.params)\n",
    "        fg = param_reg[0]\n",
    "        fm = param_reg[1]\n",
    "        fp = param_reg[2]\n",
    "        \n",
    "        k1 = known_param[0]\n",
    "        k2 = known_param[1]\n",
    "        k3 = known_param[2]\n",
    "        kd = known_param[3]\n",
    "        kd2 = known_param[4]\n",
    "        cGEM = known_param[5]\n",
    "        \n",
    "        # residual loss\n",
    "        l1 = criterion(G1_t, -k1*(1-fg)*G1 + 2*k2*(1-fm)*G2 - kd*G1)\n",
    "        l2 = criterion(G2_t, k1*(1-fg)*G1 - k2*(1-fm)*G2 - k3*(1-fp)*G2 - kd*cGEM*G2)\n",
    "        l3 = criterion(P_t, k3*(1-fp)*G2 - kd2*P)\n",
    "        l4 = criterion(D_t, kd*G1 + kd*cGEM*G2 + kd2*P)\n",
    "        \n",
    "        # data loss\n",
    "        sum_loss1 = criterion(G1, G1_tensor)\n",
    "        sum_loss2 = criterion(G2, G2_tensor)\n",
    "        sum_loss3 = criterion(P, P_tensor)\n",
    "        sum_loss4 = criterion(D, D_tensor)\n",
    "        \n",
    "        # initial conditions loss\n",
    "        G1_init_loss = criterion(G1[0], zero_init[0])\n",
    "        G2_init_loss = criterion(G2[0], zero_init[1])\n",
    "        P_init_loss = criterion(P[0], zero_init[2])\n",
    "        D_init_loss = criterion(D[0], zero_init[3])\n",
    "        \n",
    "       \n",
    "        # residual loss + data loss + initial conditions loss \n",
    "        total_loss = (l1 + l2 + l3 + l4 + \\\n",
    "                      sum_loss1 + sum_loss2 + sum_loss3 + sum_loss4 +  \\\n",
    "                      G1_init_loss + G2_init_loss + P_init_loss + D_init_loss)       \n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the learning rate based on the validation loss\n",
    "        scheduler.step(total_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 200 == 0:\n",
    "            loss_item = round(total_loss.item(), 4)\n",
    "            param_item = param_reg.data.numpy()\n",
    "            epoch_list.append(epoch+1)\n",
    "            loss_list.append(loss_item)\n",
    "            fg_list.append(param_item[0])\n",
    "            fm_list.append(param_item[1])\n",
    "            fp_list.append(param_item[2])\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}]', \n",
    "                  f'Loss: {total_loss.item():.2e}', \n",
    "                  f'params: {param_reg.data.numpy()}')\n",
    "            \n",
    "        # save list containing loss and params to csv files\n",
    "        loss_param_df = pd.DataFrame(data={\"Num Epoch\": epoch_list,\n",
    "                                           \"loss\": loss_list,\n",
    "                                           \"fg\": fg_list,\n",
    "                                           \"fm\": fm_list,\n",
    "                                           \"fp\": fp_list\n",
    "                                           })\n",
    "        loss_param_df.to_csv(\"./loss_param_1e.csv\", sep=',',index=False)\n",
    "\n",
    "    print('Training completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188a9b35-b6cc-4237-8594-235bbdc290b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19.\n",
      " 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37.\n",
      " 38. 39.]\n"
     ]
    }
   ],
   "source": [
    "t = np.linspace(2,39,38)\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc9713d-d475-4c8b-957a-70efa26c6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drug_dose_param(file,known_param,t):\n",
    "    #file = pd.read_csv('filename')\n",
    "    \n",
    "    file_D = file.iloc[0,:-1].to_numpy()\n",
    "    file_G1 = file.iloc[1,:-1].to_numpy()\n",
    "    file_G2 = file.iloc[2,:-1].to_numpy()\n",
    "    file_P = file.iloc[3,:-1].to_numpy()\n",
    "    \n",
    "    # scaling the data\n",
    "    max_file_G1 = np.max(file_G1)\n",
    "    max_file_G2 = np.max(file_G2)\n",
    "    max_file_P = np.max(file_P)\n",
    "    max_file_D = np.max(file_D)\n",
    "    \n",
    "    max_file = np.max([max_file_G1, max_file_G2, max_file_P, max_file_D])\n",
    "    ###########################################################################\n",
    "    \n",
    "    t_train = t\n",
    "    file_G1_data = file_G1 / max_file\n",
    "    file_G2_data = file_G2 / max_file\n",
    "    file_P_data = file_P / max_file\n",
    "    file_D_data = file_D / max_file\n",
    "    \n",
    "    # Set initial conditions for all variables\n",
    "    file_zero_init = np.array([file_G1_data[0], file_G2_data[0], file_P_data[0], file_D_data[0]])\n",
    "    \n",
    "    # Create and train the PINN model\n",
    "    input_size = 1; hidden_size = 32; output_size = 4; num_epochs =  6000; learning_rate = 1e-3\n",
    "    \n",
    "    model = PINN_sys(input_size, hidden_size, output_size)\n",
    "    train_pinn_sys(model,\n",
    "                   t_train, file_G1_data, file_G2_data, file_P_data,\n",
    "                   file_D_data, file_zero_init, known_param, num_epochs, learning_rate)\n",
    "    \n",
    "    # Test the trained model\n",
    "    t_test = t\n",
    "    t_test = torch.FloatTensor(t_test.reshape(-1, 1))\n",
    "    file_pred = model(t_test).detach().numpy()\n",
    "    \n",
    "    file_G1_pred = file_pred[:, 0] * max_file\n",
    "    file_G2_pred = file_pred[:, 1] * max_file\n",
    "    file_P_pred = file_pred[:, 2] * max_file\n",
    "    file_D_pred = file_pred[:, 3] * max_file\n",
    "    \n",
    "    return file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85a4fff-17a2-477a-bc65-cec458722a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cGEM_all = np.array([0, 3.125, 6.25, 12.5, 25, 50, 100, 200, 400, 800])\n",
    "\n",
    "kn_param_2N = np.array([0.06542416, 0.65263357, 0.05263728, 0.01360368, 0.00667656])\n",
    "kn_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d1c9cb-6488-4e73-ba77-9d1b10aa83eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 2.95e-03 params: [0.7900826  0.55716574 0.55686635]\n",
      "Epoch [400/6000] Loss: 1.30e-03 params: [0.669077   0.46709782 0.73614156]\n",
      "Epoch [600/6000] Loss: 1.01e-03 params: [0.547382   0.38135287 0.8968517 ]\n",
      "Epoch [800/6000] Loss: 9.20e-04 params: [0.44224542 0.30816686 1.0353366 ]\n",
      "Epoch [1000/6000] Loss: 1.00e-03 params: [0.35432494 0.2446183  1.1498189 ]\n",
      "Epoch [1200/6000] Loss: 8.14e-04 params: [0.28138453 0.18585572 1.2387947 ]\n",
      "Epoch [1400/6000] Loss: 7.87e-04 params: [0.22403896 0.13957407 1.3035587 ]\n",
      "Epoch 01518: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1600/6000] Loss: 7.72e-04 params: [0.18772925 0.11188693 1.338713  ]\n",
      "Epoch [1800/6000] Loss: 7.63e-04 params: [0.16754456 0.09171098 1.3529894 ]\n",
      "Epoch [2000/6000] Loss: 7.55e-04 params: [0.14726289 0.0729106  1.3614918 ]\n",
      "Epoch [2200/6000] Loss: 7.48e-04 params: [0.12784469 0.05539685 1.3627377 ]\n",
      "Epoch [2400/6000] Loss: 7.43e-04 params: [0.1098368  0.03920526 1.3555976 ]\n",
      "Epoch [2600/6000] Loss: 7.39e-04 params: [0.09347437 0.02437551 1.3392696 ]\n",
      "Epoch [2800/6000] Loss: 7.37e-04 params: [0.07905607 0.0123699  1.3136857 ]\n",
      "Epoch 02942: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [3000/6000] Loss: 7.33e-04 params: [0.06965282 0.00398296 1.2846788 ]\n",
      "Epoch [3200/6000] Loss: 7.32e-04 params: [6.4536959e-02 1.2617265e-06 1.2641387e+00]\n",
      "Epoch [3400/6000] Loss: 7.31e-04 params: [6.0564667e-02 2.7561186e-06 1.2403686e+00]\n",
      "Epoch [3600/6000] Loss: 7.30e-04 params: [5.7890739e-02 3.2713226e-06 1.2137474e+00]\n",
      "Epoch [3800/6000] Loss: 7.29e-04 params: [5.6050960e-02 8.2908173e-07 1.1848464e+00]\n",
      "Epoch [4000/6000] Loss: 7.28e-04 params: [5.4706633e-02 8.9265814e-07 1.1541208e+00]\n",
      "Epoch [4200/6000] Loss: 7.27e-04 params: [5.3631451e-02 2.2252207e-06 1.1219288e+00]\n",
      "Epoch [4400/6000] Loss: 7.26e-04 params: [5.2693859e-02 5.7281904e-06 1.0885538e+00]\n",
      "Epoch 04460: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [4600/6000] Loss: 7.26e-04 params: [5.2179962e-02 4.0165141e-06 1.0663235e+00]\n",
      "Epoch [4800/6000] Loss: 7.25e-04 params: [5.1726509e-02 8.9935693e-06 1.0486003e+00]\n",
      "Epoch [5000/6000] Loss: 7.25e-04 params: [5.1264197e-02 6.3193152e-06 1.0303005e+00]\n",
      "Epoch [5200/6000] Loss: 7.24e-04 params: [5.0795320e-02 8.8676552e-06 1.0114906e+00]\n",
      "Epoch [5400/6000] Loss: 7.24e-04 params: [5.0323084e-02 2.3079633e-06 9.9223691e-01]\n",
      "Epoch [5600/6000] Loss: 7.23e-04 params: [4.9850527e-02 2.3973303e-06 9.7260475e-01]\n",
      "Epoch [5800/6000] Loss: 7.23e-04 params: [4.938148e-02 9.018946e-07 9.526578e-01]\n",
      "Epoch 05991: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch [6000/6000] Loss: 7.23e-04 params: [4.8942767e-02 3.3381486e-05 9.3288296e-01]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 4N\n",
    "# E_3, cGEM=3.125\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 3.125])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/E_3.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43d3146-2748-4b91-8bf5-0aa3439fe79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.048942767\n",
      "fm=3.3381486e-05\n",
      "fp=0.93288296\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7614a67-6478-432f-808a-a9ee1140f87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 6.19e-03 params: [0.91036344 0.84215    0.82518077]\n",
      "Epoch [400/6000] Loss: 2.14e-03 params: [0.89859086 0.7593382  1.0601972 ]\n",
      "Epoch [600/6000] Loss: 2.63e-03 params: [0.80131775 0.6994678  1.2705611 ]\n",
      "Epoch [800/6000] Loss: 1.31e-03 params: [0.68327594 0.63800454 1.4461793 ]\n",
      "Epoch [1000/6000] Loss: 1.21e-03 params: [0.56349224 0.57730997 1.5888922 ]\n",
      "Epoch 01077: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1200/6000] Loss: 1.17e-03 params: [0.48352373 0.5369295  1.668503  ]\n",
      "Epoch [1400/6000] Loss: 1.14e-03 params: [0.4267149 0.5077612 1.7168474]\n",
      "Epoch [1600/6000] Loss: 1.11e-03 params: [0.3707694  0.47884113 1.7565753 ]\n",
      "Epoch [1800/6000] Loss: 1.08e-03 params: [0.31659526 0.4507524  1.7858624 ]\n",
      "Epoch [2000/6000] Loss: 1.06e-03 params: [0.26497436 0.42392677 1.8028312 ]\n",
      "Epoch [2200/6000] Loss: 1.05e-03 params: [0.21653275 0.39882547 1.8057011 ]\n",
      "Epoch [2400/6000] Loss: 1.06e-03 params: [0.17184214 0.37569228 1.7929025 ]\n",
      "Epoch [2600/6000] Loss: 1.02e-03 params: [0.13126151 0.35493493 1.7635081 ]\n",
      "Epoch [2800/6000] Loss: 1.01e-03 params: [0.09487826 0.33641726 1.7172171 ]\n",
      "Epoch [3000/6000] Loss: 1.00e-03 params: [0.06275891 0.32010835 1.6551603 ]\n",
      "Epoch [3200/6000] Loss: 9.86e-04 params: [0.03457691 0.30598792 1.5797937 ]\n",
      "Epoch 03263: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [3400/6000] Loss: 9.81e-04 params: [0.01791281 0.29794392 1.5240669 ]\n",
      "Epoch [3600/6000] Loss: 9.77e-04 params: [0.00583959 0.29187447 1.4787492 ]\n",
      "Epoch [3800/6000] Loss: 9.72e-04 params: [2.5602130e-05 2.8644419e-01 1.4317322e+00]\n",
      "Epoch [4000/6000] Loss: 9.68e-04 params: [3.3407003e-05 2.8396153e-01 1.3861240e+00]\n",
      "Epoch [4200/6000] Loss: 9.63e-04 params: [3.9567913e-05 2.8307441e-01 1.3416879e+00]\n",
      "Epoch [4400/6000] Loss: 9.59e-04 params: [4.4890548e-05 2.8284597e-01 1.2980261e+00]\n",
      "Epoch [4600/6000] Loss: 9.55e-04 params: [5.002423e-05 2.829122e-01 1.254987e+00]\n",
      "Epoch [4800/6000] Loss: 9.52e-04 params: [1.41760365e-05 2.83229828e-01 1.21253467e+00]\n",
      "Epoch [5000/6000] Loss: 9.63e-04 params: [3.1367435e-05 2.8366014e-01 1.1706580e+00]\n",
      "Epoch 05001: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [5200/6000] Loss: 9.46e-04 params: [4.8652878e-06 2.8392795e-01 1.1496094e+00]\n",
      "Epoch [5400/6000] Loss: 9.44e-04 params: [5.1254724e-06 2.8411001e-01 1.1285937e+00]\n",
      "Epoch [5600/6000] Loss: 9.42e-04 params: [5.3314689e-06 2.8429735e-01 1.1074532e+00]\n",
      "Epoch [5800/6000] Loss: 9.40e-04 params: [5.5833139e-06 2.8450719e-01 1.0862249e+00]\n",
      "Epoch [6000/6000] Loss: 9.38e-04 params: [5.8532105e-06 2.8474462e-01 1.0649403e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# F_3, cGEM=3.125\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 3.125])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/F_3.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c6e3c5-7509-4a8f-b007-f95cc72ae41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=5.8532105e-06\n",
      "fm=0.28474462\n",
      "fp=1.0649403\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec8fd1ec-5328-47bb-98dd-71a463db8bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 4.89e-03 params: [0.64719075 0.7150366  0.3500431 ]\n",
      "Epoch [400/6000] Loss: 2.13e-03 params: [0.7190191  0.63528603 0.46530282]\n",
      "Epoch [600/6000] Loss: 1.62e-03 params: [0.7035904  0.58108157 0.6383437 ]\n",
      "Epoch 00757: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [800/6000] Loss: 1.46e-03 params: [0.65507454 0.53899103 0.79540837]\n",
      "Epoch [1000/6000] Loss: 1.38e-03 params: [0.62060285 0.51495224 0.87977415]\n",
      "Epoch [1200/6000] Loss: 1.32e-03 params: [0.5823773 0.4895687 0.9612776]\n",
      "Epoch [1400/6000] Loss: 1.26e-03 params: [0.5418113 0.4631621 1.0389299]\n",
      "Epoch [1600/6000] Loss: 1.21e-03 params: [0.4999792 0.4360487 1.111968 ]\n",
      "Epoch [1800/6000] Loss: 1.18e-03 params: [0.4576593  0.40857035 1.1797365 ]\n",
      "Epoch [2000/6000] Loss: 1.15e-03 params: [0.4155669 0.3810261 1.2415457]\n",
      "Epoch [2200/6000] Loss: 1.13e-03 params: [0.37421328 0.35360873 1.2966571 ]\n",
      "Epoch [2400/6000] Loss: 2.64e-03 params: [0.3339743  0.32640508 1.3441639 ]\n",
      "Epoch [2600/6000] Loss: 1.09e-03 params: [0.29485002 0.29952332 1.3831462 ]\n",
      "Epoch [2800/6000] Loss: 1.07e-03 params: [0.25704333 0.27307707 1.4123917 ]\n",
      "Epoch [3000/6000] Loss: 1.06e-03 params: [0.22076398 0.24722601 1.4305389 ]\n",
      "Epoch [3200/6000] Loss: 1.07e-03 params: [0.18614952 0.22214162 1.4360569 ]\n",
      "Epoch [3400/6000] Loss: 1.04e-03 params: [0.15316832 0.19819124 1.4275968 ]\n",
      "Epoch [3600/6000] Loss: 1.03e-03 params: [0.12224218 0.17548242 1.4038086 ]\n",
      "Epoch [3800/6000] Loss: 1.07e-03 params: [0.0939351  0.15422934 1.3639678 ]\n",
      "Epoch 03834: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [4000/6000] Loss: 1.02e-03 params: [0.07798339 0.14258994 1.3328726 ]\n",
      "Epoch [4200/6000] Loss: 1.01e-03 params: [0.06481646 0.13255554 1.301025  ]\n",
      "Epoch [4400/6000] Loss: 1.01e-03 params: [0.05165268 0.12246953 1.2644161 ]\n",
      "Epoch [4600/6000] Loss: 1.01e-03 params: [0.03857495 0.11243279 1.2233928 ]\n",
      "Epoch [4800/6000] Loss: 1.01e-03 params: [0.02570432 0.10254909 1.1785036 ]\n",
      "Epoch [5000/6000] Loss: 1.00e-03 params: [0.01317552 0.09291121 1.1304332 ]\n",
      "Epoch [5200/6000] Loss: 1.00e-03 params: [0.00111531 0.08360381 1.0799186 ]\n",
      "Epoch [5400/6000] Loss: 9.97e-04 params: [1.8120787e-05 7.5842068e-02 1.0294824e+00]\n",
      "Epoch 05449: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [5600/6000] Loss: 9.96e-04 params: [7.5763469e-06 7.2473608e-02 9.9938464e-01]\n",
      "Epoch [5800/6000] Loss: 9.95e-04 params: [3.1923037e-06 7.0276171e-02 9.7579527e-01]\n",
      "Epoch [6000/6000] Loss: 9.93e-04 params: [1.2257206e-06 6.8456426e-02 9.5251763e-01]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# G_3, cGEM=3.125\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 3.125])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/G_3.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8081cf-3826-42f1-aaf8-7d6a7151cf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=1.2257206e-06\n",
      "fm=0.068456426\n",
      "fp=0.9525176\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3362a44-afad-478a-9bf1-86805a166af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 7.18e-03 params: [0.8699785  0.55540156 0.7008266 ]\n",
      "Epoch [400/6000] Loss: 3.03e-03 params: [0.8104594  0.55200076 0.73886025]\n",
      "Epoch [600/6000] Loss: 2.25e-03 params: [0.7638028  0.5413792  0.78623724]\n",
      "Epoch [800/6000] Loss: 1.90e-03 params: [0.72501737 0.5248829  0.8397498 ]\n",
      "Epoch [1000/6000] Loss: 1.62e-03 params: [0.6883122  0.50418043 0.89848804]\n",
      "Epoch 01019: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1200/6000] Loss: 1.49e-03 params: [0.66722876 0.49113604 0.9334135 ]\n",
      "Epoch [1400/6000] Loss: 1.41e-03 params: [0.6466611  0.47767216 0.9681043 ]\n",
      "Epoch [1600/6000] Loss: 1.34e-03 params: [0.6246537 0.4627943 1.005194 ]\n",
      "Epoch [1800/6000] Loss: 1.28e-03 params: [0.6012313  0.44661033 1.0442592 ]\n",
      "Epoch [2000/6000] Loss: 1.24e-03 params: [0.5765022  0.42925745 1.0848682 ]\n",
      "Epoch [2200/6000] Loss: 1.25e-03 params: [0.55057037 0.41083553 1.1265827 ]\n",
      "Epoch 02206: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [2400/6000] Loss: 1.18e-03 params: [0.5363186 0.4006984 1.1488389]\n",
      "Epoch [2600/6000] Loss: 1.16e-03 params: [0.5216656  0.39012957 1.1713479 ]\n",
      "Epoch [2800/6000] Loss: 1.14e-03 params: [0.506144   0.37880337 1.1946812 ]\n",
      "Epoch [3000/6000] Loss: 1.12e-03 params: [0.4897758  0.36673024 1.2186682 ]\n",
      "Epoch [3200/6000] Loss: 1.09e-03 params: [0.47259596 0.35392618 1.243123  ]\n",
      "Epoch [3400/6000] Loss: 1.60e-03 params: [0.45465612 0.34041333 1.2678429 ]\n",
      "Epoch [3600/6000] Loss: 1.05e-03 params: [0.43603325 0.3262414  1.2926297 ]\n",
      "Epoch [3800/6000] Loss: 1.04e-03 params: [0.41678047 0.31144685 1.3172606 ]\n",
      "Epoch [4000/6000] Loss: 1.02e-03 params: [0.3970001  0.29607198 1.3414937 ]\n",
      "Epoch [4200/6000] Loss: 1.01e-03 params: [0.37680304 0.28016534 1.3650721 ]\n",
      "Epoch [4400/6000] Loss: 9.99e-04 params: [0.35630882 0.26377618 1.3877244 ]\n",
      "Epoch [4600/6000] Loss: 9.78e-04 params: [0.3353967 0.2469482 1.4091402]\n",
      "Epoch [4800/6000] Loss: 9.66e-04 params: [0.31450284 0.22974893 1.4289826 ]\n",
      "Epoch [5000/6000] Loss: 9.54e-04 params: [0.2935638 0.2122246 1.4468852]\n",
      "Epoch [5200/6000] Loss: 9.44e-04 params: [0.27267405 0.19443573 1.4624411 ]\n",
      "Epoch [5400/6000] Loss: 1.15e-03 params: [0.25182542 0.17642401 1.4751823 ]\n",
      "Epoch 05415: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [5600/6000] Loss: 9.28e-04 params: [0.24045467 0.16648054 1.4807465 ]\n",
      "Epoch [5800/6000] Loss: 9.23e-04 params: [0.22950065 0.15682265 1.485081  ]\n",
      "Epoch [6000/6000] Loss: 9.17e-04 params: [0.21821547 0.14673647 1.4883664 ]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# H_3, cGEM=3.125\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 3.125])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/H_3.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ca8636-c88f-4116-8731-8ebdc895b165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.21821547\n",
      "fm=0.14673647\n",
      "fp=1.4883664\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9932e36c-87ce-43cd-8c8b-00ae0e779d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 8.65e-03 params: [0.50654876 0.46612468 0.95661294]\n",
      "Epoch [400/6000] Loss: 3.65e-03 params: [0.3539896 0.5539567 1.1263076]\n",
      "Epoch [600/6000] Loss: 3.27e-03 params: [0.2732552 0.5785435 1.2647848]\n",
      "Epoch [800/6000] Loss: 2.22e-03 params: [0.22508839 0.570469   1.3843732 ]\n",
      "Epoch [1000/6000] Loss: 2.01e-03 params: [0.1887965 0.5615072 1.498878 ]\n",
      "Epoch [1200/6000] Loss: 1.89e-03 params: [0.16626857 0.5586441  1.6126375 ]\n",
      "Epoch 01298: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1400/6000] Loss: 1.83e-03 params: [0.16096406 0.5609481  1.6999015 ]\n",
      "Epoch [1600/6000] Loss: 1.80e-03 params: [0.16340415 0.56384146 1.7625439 ]\n",
      "Epoch [1800/6000] Loss: 1.77e-03 params: [0.17074579 0.56807214 1.8299055 ]\n",
      "Epoch [2000/6000] Loss: 1.74e-03 params: [0.18271402 0.5735494  1.9024477 ]\n",
      "Epoch [2200/6000] Loss: 1.72e-03 params: [0.1989736 0.5801408 1.9805183]\n",
      "Epoch [2400/6000] Loss: 1.70e-03 params: [0.21892889 0.5876233  2.0642133 ]\n",
      "Epoch 02490: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [2600/6000] Loss: 1.70e-03 params: [0.23551139 0.5937224  2.1286206 ]\n",
      "Epoch [2800/6000] Loss: 1.69e-03 params: [0.24824128 0.59814215 2.1749263 ]\n",
      "Epoch [3000/6000] Loss: 1.68e-03 params: [0.26203755 0.6028392  2.2228208 ]\n",
      "Epoch [3200/6000] Loss: 1.68e-03 params: [0.276739  0.6078328 2.2721436]\n",
      "Epoch [3400/6000] Loss: 1.67e-03 params: [0.29228374 0.6131103  2.322731  ]\n",
      "Epoch [3600/6000] Loss: 1.67e-03 params: [0.30859149 0.61863214 2.3744192 ]\n",
      "Epoch [3800/6000] Loss: 1.66e-03 params: [0.32554543 0.62435097 2.4270449 ]\n",
      "Epoch [4000/6000] Loss: 1.66e-03 params: [0.34305263 0.6302958  2.4804451 ]\n",
      "Epoch [4200/6000] Loss: 1.66e-03 params: [0.3608528 0.6361748 2.5344515]\n",
      "Epoch [4400/6000] Loss: 1.65e-03 params: [0.37871668 0.64210314 2.5888875 ]\n",
      "Epoch 04506: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [4600/6000] Loss: 1.65e-03 params: [0.39235094 0.64661354 2.630829  ]\n",
      "Epoch [4800/6000] Loss: 1.65e-03 params: [0.40141997 0.6495749  2.6580074 ]\n",
      "Epoch [5000/6000] Loss: 1.65e-03 params: [0.4107081 0.6526199 2.6850433]\n",
      "Epoch [5200/6000] Loss: 1.65e-03 params: [0.42017114 0.6557434  2.7119796 ]\n",
      "Epoch [5400/6000] Loss: 1.65e-03 params: [0.4297851  0.65892655 2.7388458 ]\n",
      "Epoch [5600/6000] Loss: 1.65e-03 params: [0.4395028 0.6621446 2.765659 ]\n",
      "Epoch [5800/6000] Loss: 1.64e-03 params: [0.4492621 0.6653715 2.7924283]\n",
      "Epoch [6000/6000] Loss: 1.64e-03 params: [0.4589899  0.66858166 2.8191557 ]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# E_4, cGEM=6.25\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 6.25])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/E_4.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e70a30e-3a61-480e-a555-2a857730717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.4589899\n",
      "fm=0.66858166\n",
      "fp=2.8191557\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b471e26-4e4f-4288-b5c4-357a5d4628d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 7.40e-03 params: [0.23207232 0.29486787 0.3389863 ]\n",
      "Epoch [400/6000] Loss: 4.11e-03 params: [0.05155976 0.4348282  0.49423283]\n",
      "Epoch [600/6000] Loss: 2.58e-03 params: [3.8245311e-05 5.6002265e-01 6.2848109e-01]\n",
      "Epoch [800/6000] Loss: 2.33e-03 params: [3.0011999e-05 6.1894697e-01 7.2445810e-01]\n",
      "Epoch [1000/6000] Loss: 2.19e-03 params: [1.6837857e-06 6.3132846e-01 7.9398698e-01]\n",
      "Epoch [1200/6000] Loss: 2.10e-03 params: [7.7209393e-07 6.3416630e-01 8.6070514e-01]\n",
      "Epoch [1400/6000] Loss: 2.04e-03 params: [3.0799777e-07 6.3629919e-01 9.3042845e-01]\n",
      "Epoch [1600/6000] Loss: 2.00e-03 params: [3.6225831e-06 6.3838667e-01 1.0033871e+00]\n",
      "Epoch [1800/6000] Loss: 1.96e-03 params: [3.9661629e-04 6.3907862e-01 1.0780467e+00]\n",
      "Epoch 01868: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [2000/6000] Loss: 1.95e-03 params: [0.00288865 0.6406101  1.1306925 ]\n",
      "Epoch [2200/6000] Loss: 1.94e-03 params: [0.00616376 0.6413444  1.1722966 ]\n",
      "Epoch [2400/6000] Loss: 1.93e-03 params: [0.01048627 0.6424958  1.2166077 ]\n",
      "Epoch [2600/6000] Loss: 1.92e-03 params: [0.01604365 0.6440181  1.2637484 ]\n",
      "Epoch [2800/6000] Loss: 1.92e-03 params: [0.02293657 0.6458606  1.3138477 ]\n",
      "Epoch [3000/6000] Loss: 1.91e-03 params: [0.0310948 0.6479513 1.366976 ]\n",
      "Epoch [3200/6000] Loss: 1.90e-03 params: [0.04030267 0.65021795 1.4231011 ]\n",
      "Epoch [3400/6000] Loss: 1.92e-03 params: [0.05026546 0.6525929  1.4820533 ]\n",
      "Epoch [3600/6000] Loss: 1.89e-03 params: [0.06103078 0.6551719  1.5436873 ]\n",
      "Epoch [3800/6000] Loss: 1.88e-03 params: [0.07192092 0.65775234 1.6071367 ]\n",
      "Epoch 03960: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [4000/6000] Loss: 1.88e-03 params: [0.08152566 0.6601571  1.6654353 ]\n",
      "Epoch [4200/6000] Loss: 1.88e-03 params: [0.08709349 0.66117173 1.6984596 ]\n",
      "Epoch [4400/6000] Loss: 1.87e-03 params: [0.09258857 0.6623658  1.7324972 ]\n",
      "Epoch [4600/6000] Loss: 1.87e-03 params: [0.09818985 0.6636529  1.7674322 ]\n",
      "Epoch [4800/6000] Loss: 1.87e-03 params: [0.10394774 0.66499865 1.8032002 ]\n",
      "Epoch [5000/6000] Loss: 1.86e-03 params: [0.10983179 0.6663822  1.8397248 ]\n",
      "Epoch [5200/6000] Loss: 1.86e-03 params: [0.11578327 0.66778433 1.8769081 ]\n",
      "Epoch [5400/6000] Loss: 1.86e-03 params: [0.12173719 0.66918784 1.9146341 ]\n",
      "Epoch [5600/6000] Loss: 1.86e-03 params: [0.1276579 0.6707238 1.9528129]\n",
      "Epoch [5800/6000] Loss: 1.86e-03 params: [0.13357864 0.6719705  1.9911131 ]\n",
      "Epoch [6000/6000] Loss: 1.85e-03 params: [0.13935164 0.67333984 2.0293932 ]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# F_4, cGEM=6.25\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 6.25])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/F_4.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91df96cb-8572-4ef1-9b57-e0aa942021aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.13935164\n",
      "fm=0.67333984\n",
      "fp=2.0293932\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33d38cb0-6e14-455f-94c5-9ad20e543b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 6.48e-03 params: [0.6609618  0.6503072  0.94132113]\n",
      "Epoch [400/6000] Loss: 2.26e-03 params: [0.52967525 0.53618556 1.1308647 ]\n",
      "Epoch [600/6000] Loss: 1.84e-03 params: [0.36244768 0.44304913 1.2751057 ]\n",
      "Epoch [800/6000] Loss: 1.62e-03 params: [0.22133322 0.36815974 1.3640782 ]\n",
      "Epoch [1000/6000] Loss: 1.50e-03 params: [0.11239699 0.31138977 1.3965391 ]\n",
      "Epoch 01074: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1200/6000] Loss: 1.45e-03 params: [0.05491378 0.28252387 1.3855668 ]\n",
      "Epoch [1400/6000] Loss: 1.40e-03 params: [0.01943148 0.2633943  1.358479  ]\n",
      "Epoch [1600/6000] Loss: 1.36e-03 params: [1.2324166e-05 2.4693964e-01 1.3150966e+00]\n",
      "Epoch [1800/6000] Loss: 1.33e-03 params: [2.7438762e-05 2.3947307e-01 1.2675300e+00]\n",
      "Epoch [2000/6000] Loss: 1.30e-03 params: [1.9075122e-05 2.3686646e-01 1.2174305e+00]\n",
      "Epoch [2200/6000] Loss: 1.28e-03 params: [1.3222895e-05 2.3654036e-01 1.1644006e+00]\n",
      "Epoch [2400/6000] Loss: 1.27e-03 params: [2.3259439e-05 2.3629908e-01 1.1091214e+00]\n",
      "Epoch [2600/6000] Loss: 1.25e-03 params: [3.2918564e-05 2.3664069e-01 1.0524334e+00]\n",
      "Epoch 02774: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [2800/6000] Loss: 1.25e-03 params: [5.3146750e-06 2.3685594e-01 9.9881482e-01]\n",
      "Epoch [3000/6000] Loss: 1.24e-03 params: [9.3242652e-06 2.3682743e-01 9.6988064e-01]\n",
      "Epoch [3200/6000] Loss: 1.24e-03 params: [2.3613531e-05 2.3640871e-01 9.4015205e-01]\n",
      "Epoch [3400/6000] Loss: 1.24e-03 params: [2.8978284e-05 2.3616993e-01 9.0989983e-01]\n",
      "Epoch [3600/6000] Loss: 1.23e-03 params: [2.1649083e-05 2.3610322e-01 8.7929976e-01]\n",
      "Epoch [3800/6000] Loss: 1.23e-03 params: [1.6102171e-05 2.3613258e-01 8.4853423e-01]\n",
      "Epoch [4000/6000] Loss: 1.23e-03 params: [3.3219905e-05 2.3623034e-01 8.1780529e-01]\n",
      "Epoch [4200/6000] Loss: 1.23e-03 params: [2.2485732e-05 2.3639281e-01 7.8731245e-01]\n",
      "Epoch 04342: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [4400/6000] Loss: 1.23e-03 params: [2.8882823e-08 2.3683420e-01 7.6153105e-01]\n",
      "Epoch [4600/6000] Loss: 1.22e-03 params: [3.5688296e-05 2.3687492e-01 7.4637449e-01]\n",
      "Epoch [4800/6000] Loss: 1.22e-03 params: [1.6381136e-06 2.3692586e-01 7.3095936e-01]\n",
      "Epoch [5000/6000] Loss: 1.22e-03 params: [1.0668404e-05 2.3703921e-01 7.1533847e-01]\n",
      "Epoch [5200/6000] Loss: 1.22e-03 params: [2.7240814e-05 2.3718886e-01 6.9956219e-01]\n",
      "Epoch [5400/6000] Loss: 1.22e-03 params: [3.2838299e-05 2.3735912e-01 6.8369007e-01]\n",
      "Epoch [5600/6000] Loss: 1.22e-03 params: [2.8636809e-05 2.3753518e-01 6.6777092e-01]\n",
      "Epoch [5800/6000] Loss: 1.22e-03 params: [2.8027211e-05 2.3771718e-01 6.5186226e-01]\n",
      "Epoch 05918: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch [6000/6000] Loss: 1.22e-03 params: [2.0507825e-06 2.3787631e-01 6.3920540e-01]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# G_4, cGEM=6.25\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 6.25])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/G_4.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e98bca44-3cc3-4762-bbda-120dd39e58d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=2.0507825e-06\n",
      "fm=0.23787631\n",
      "fp=0.6392054\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4db59ca1-7730-4cb2-8efb-af23e62d020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 6.72e-03 params: [0.02408314 0.35485092 0.56785923]\n",
      "Epoch [400/6000] Loss: 1.95e-03 params: [0.06352835 0.34804818 0.57444584]\n",
      "Epoch [600/6000] Loss: 1.61e-03 params: [0.10727253 0.33976546 0.5864912 ]\n",
      "Epoch [800/6000] Loss: 1.34e-03 params: [0.13827239 0.3313536  0.6048834 ]\n",
      "Epoch [1000/6000] Loss: 1.24e-03 params: [0.15391527 0.32314444 0.62948704]\n",
      "Epoch 01151: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1200/6000] Loss: 1.18e-03 params: [0.15767936 0.3159979  0.65553564]\n",
      "Epoch [1400/6000] Loss: 1.13e-03 params: [0.15629737 0.31165704 0.6726323 ]\n",
      "Epoch [1600/6000] Loss: 1.09e-03 params: [0.15324453 0.3069469  0.6917439 ]\n",
      "Epoch [1800/6000] Loss: 1.06e-03 params: [0.14850186 0.30185568 0.71275544]\n",
      "Epoch [2000/6000] Loss: 1.03e-03 params: [0.14227493 0.29636902 0.7355268 ]\n",
      "Epoch [2200/6000] Loss: 1.20e-03 params: [0.13497694 0.2905008  0.75992775]\n",
      "Epoch [2400/6000] Loss: 9.81e-04 params: [0.12640938 0.28423354 0.7858284 ]\n",
      "Epoch 02472: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [2600/6000] Loss: 9.71e-04 params: [0.12025124 0.27974036 0.8044502 ]\n",
      "Epoch [2800/6000] Loss: 9.62e-04 params: [0.11508751 0.2761191  0.81911594]\n",
      "Epoch [3000/6000] Loss: 9.53e-04 params: [0.1095056  0.27219504 0.83473825]\n",
      "Epoch [3200/6000] Loss: 9.44e-04 params: [0.10346293 0.26796192 0.8512826 ]\n",
      "Epoch [3400/6000] Loss: 9.36e-04 params: [0.09696089 0.26341492 0.8686977 ]\n",
      "Epoch [3600/6000] Loss: 9.28e-04 params: [0.09000578 0.25855055 0.8869159 ]\n",
      "Epoch [3800/6000] Loss: 9.21e-04 params: [0.08260411 0.25336692 0.90585124]\n",
      "Epoch [4000/6000] Loss: 9.15e-04 params: [0.07489443 0.2479037  0.9254432 ]\n",
      "Epoch [4200/6000] Loss: 9.10e-04 params: [0.06684981 0.2421489  0.94556224]\n",
      "Epoch [4400/6000] Loss: 9.05e-04 params: [0.05830725 0.23609354 0.9660772 ]\n",
      "Epoch [4600/6000] Loss: 9.01e-04 params: [0.04955348 0.22978853 0.9868474 ]\n",
      "Epoch 04703: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [4800/6000] Loss: 8.99e-04 params: [0.04278886 0.22482736 1.0027394 ]\n",
      "Epoch [5000/6000] Loss: 8.96e-04 params: [0.03791139 0.22132197 1.0135444 ]\n",
      "Epoch [5200/6000] Loss: 8.94e-04 params: [0.03272798 0.2175748  1.024686  ]\n",
      "Epoch [5400/6000] Loss: 8.92e-04 params: [0.02720675 0.21358007 1.0360929 ]\n",
      "Epoch [5600/6000] Loss: 8.90e-04 params: [0.02134451 0.20933264 1.04768   ]\n",
      "Epoch [5800/6000] Loss: 8.88e-04 params: [0.01513834 0.20482859 1.0593544 ]\n",
      "Epoch [6000/6000] Loss: 8.86e-04 params: [0.00858743 0.20006588 1.0710055 ]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# H_4, cGEM=6.25\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 6.25])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/H_4.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "912fb5b0-eed0-4ee2-a4f7-fc4729a82c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.008587429\n",
      "fm=0.20006588\n",
      "fp=1.0710055\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53e19c9c-f2c5-4f2e-ae54-924c01e05bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 2.21e-02 params: [0.04167582 0.13234228 0.7279554 ]\n",
      "Epoch [400/6000] Loss: 1.55e-02 params: [7.5442760e-05 1.6092917e-01 7.5886238e-01]\n",
      "Epoch [600/6000] Loss: 1.46e-02 params: [7.105259e-05 2.026836e-01 8.045382e-01]\n",
      "Epoch [800/6000] Loss: 1.34e-02 params: [1.5406906e-04 2.5857297e-01 8.6615521e-01]\n",
      "Epoch [1000/6000] Loss: 1.22e-02 params: [9.7901153e-05 3.3144996e-01 9.4721591e-01]\n",
      "Epoch [1200/6000] Loss: 1.07e-02 params: [1.8581351e-05 4.2569041e-01 1.0534973e+00]\n",
      "Epoch [1400/6000] Loss: 8.76e-03 params: [1.0879032e-04 5.4464400e-01 1.1912340e+00]\n",
      "Epoch [1600/6000] Loss: 6.17e-03 params: [7.1010756e-05 6.7795599e-01 1.3563069e+00]\n",
      "Epoch [1800/6000] Loss: 4.75e-03 params: [7.8761732e-05 7.7880228e-01 1.5111173e+00]\n",
      "Epoch [2000/6000] Loss: 4.27e-03 params: [9.4737425e-06 8.1813985e-01 1.6266363e+00]\n",
      "Epoch [2200/6000] Loss: 3.90e-03 params: [1.0951964e-05 8.2906258e-01 1.7262198e+00]\n",
      "Epoch [2400/6000] Loss: 3.64e-03 params: [5.0278140e-07 8.3515066e-01 1.8304974e+00]\n",
      "Epoch [2600/6000] Loss: 3.49e-03 params: [1.5061827e-03 8.3986342e-01 1.9439453e+00]\n",
      "Epoch [2800/6000] Loss: 3.38e-03 params: [0.01047284 0.8431365  2.0651503 ]\n",
      "Epoch [3000/6000] Loss: 3.32e-03 params: [0.02510047 0.8460139  2.1917622 ]\n",
      "Epoch [3200/6000] Loss: 3.28e-03 params: [0.04349882 0.8478396  2.3197854 ]\n",
      "Epoch 03244: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [3400/6000] Loss: 3.26e-03 params: [0.05625898 0.849489   2.3994236 ]\n",
      "Epoch [3600/6000] Loss: 3.25e-03 params: [0.06797574 0.8503705  2.4655201 ]\n",
      "Epoch [3800/6000] Loss: 3.23e-03 params: [0.08064971 0.8514374  2.5328076 ]\n",
      "Epoch [4000/6000] Loss: 3.22e-03 params: [0.09437754 0.8526393  2.6009843 ]\n",
      "Epoch [4200/6000] Loss: 3.21e-03 params: [0.10916857 0.8539414  2.6697657 ]\n",
      "Epoch [4400/6000] Loss: 3.19e-03 params: [0.12496778 0.8553323  2.7389176 ]\n",
      "Epoch [4600/6000] Loss: 3.18e-03 params: [0.14168298 0.8568079  2.808256  ]\n",
      "Epoch [4800/6000] Loss: 3.16e-03 params: [0.1591954  0.85836124 2.8776243 ]\n",
      "Epoch [5000/6000] Loss: 3.14e-03 params: [0.1773603 0.8599802 2.9468791]\n",
      "Epoch [5200/6000] Loss: 3.13e-03 params: [0.19603223 0.8617669  3.0159972 ]\n",
      "Epoch [5400/6000] Loss: 3.82e-03 params: [0.21498498 0.863355   3.0846164 ]\n",
      "Epoch [5600/6000] Loss: 3.10e-03 params: [0.2339624 0.8650632 3.1527796]\n",
      "Epoch [5800/6000] Loss: 3.09e-03 params: [0.25259316 0.8668113  3.2200973 ]\n",
      "Epoch [6000/6000] Loss: 3.08e-03 params: [0.27072486 0.86827725 3.2862406 ]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# E_5, cGEM=12.5\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 12.5])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/E_5.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b12eff5f-92bd-4010-b38e-07f4aadbeb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.27072486\n",
      "fm=0.86827725\n",
      "fp=3.2862406\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60af64e1-332e-49f2-97b2-09c65ee4cec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 1.96e-02 params: [0.5473143  0.80745435 0.4632913 ]\n",
      "Epoch [400/6000] Loss: 6.86e-03 params: [0.42729315 0.92506826 0.65451014]\n",
      "Epoch [600/6000] Loss: 5.71e-03 params: [0.37921104 0.936849   0.79976875]\n",
      "Epoch [800/6000] Loss: 4.89e-03 params: [0.33508804 0.9327028  0.942551  ]\n",
      "Epoch [1000/6000] Loss: 4.60e-03 params: [0.28453553 0.92813003 1.0852208 ]\n",
      "Epoch [1200/6000] Loss: 4.41e-03 params: [0.22842109 0.92351174 1.2247622 ]\n",
      "Epoch [1400/6000] Loss: 4.26e-03 params: [0.1677595  0.91886896 1.3588872 ]\n",
      "Epoch [1600/6000] Loss: 4.08e-03 params: [0.1035912 0.9138877 1.4855744]\n",
      "Epoch [1800/6000] Loss: 3.91e-03 params: [0.03659626 0.9092439  1.603386  ]\n",
      "Epoch [2000/6000] Loss: 3.80e-03 params: [2.3530987e-05 9.0624446e-01 1.7120862e+00]\n",
      "Epoch [2200/6000] Loss: 4.34e-03 params: [6.4840118e-05 9.0600836e-01 1.8169913e+00]\n",
      "Epoch 02212: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [2400/6000] Loss: 3.71e-03 params: [3.0465015e-05 9.0586644e-01 1.8723667e+00]\n",
      "Epoch [2600/6000] Loss: 3.69e-03 params: [3.3580141e-05 9.0556943e-01 1.9253796e+00]\n",
      "Epoch [2800/6000] Loss: 3.67e-03 params: [3.1664298e-05 9.0533012e-01 1.9790989e+00]\n",
      "Epoch [3000/6000] Loss: 3.65e-03 params: [9.4446768e-06 9.0511101e-01 2.0332441e+00]\n",
      "Epoch [3200/6000] Loss: 3.63e-03 params: [1.0629432e-05 9.0490794e-01 2.0875428e+00]\n",
      "Epoch [3400/6000] Loss: 3.62e-03 params: [3.8830261e-05 9.0471524e-01 2.1416838e+00]\n",
      "Epoch [3600/6000] Loss: 3.61e-03 params: [4.2893451e-05 9.0452808e-01 2.1953428e+00]\n",
      "Epoch 03692: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [3800/6000] Loss: 3.60e-03 params: [1.20283585e-05 9.04499650e-01 2.23428488e+00]\n",
      "Epoch [4000/6000] Loss: 3.59e-03 params: [2.2711229e-05 9.0434784e-01 2.2613592e+00]\n",
      "Epoch [4200/6000] Loss: 3.59e-03 params: [1.4840876e-05 9.0423071e-01 2.2889321e+00]\n",
      "Epoch [4400/6000] Loss: 3.58e-03 params: [2.3530767e-05 9.0412164e-01 2.3168607e+00]\n",
      "Epoch [4600/6000] Loss: 3.58e-03 params: [1.8268951e-05 9.0401518e-01 2.3450091e+00]\n",
      "Epoch [4800/6000] Loss: 3.57e-03 params: [2.2273227e-05 9.0391272e-01 2.3732378e+00]\n",
      "Epoch [5000/6000] Loss: 3.57e-03 params: [2.1199401e-05 9.0381247e-01 2.4013953e+00]\n",
      "Epoch [5200/6000] Loss: 3.56e-03 params: [1.6215719e-05 9.0371478e-01 2.4293373e+00]\n",
      "Epoch [5400/6000] Loss: 3.56e-03 params: [3.3255965e-05 9.0363902e-01 2.4569228e+00]\n",
      "Epoch [5600/6000] Loss: 3.56e-03 params: [7.637656e-06 9.035692e-01 2.484002e+00]\n",
      "Epoch [5800/6000] Loss: 3.55e-03 params: [6.0762832e-06 9.0344864e-01 2.5104148e+00]\n",
      "Epoch 05832: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [6000/6000] Loss: 3.55e-03 params: [1.5408150e-06 9.0340978e-01 2.5255768e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# F_5, cGEM=12.5\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 12.5])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/F_5.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e717fce5-00cf-4027-97bf-8492586cbc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=1.540815e-06\n",
      "fm=0.9034098\n",
      "fp=2.5255768\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "116c1149-5295-4369-917e-e3ca90313fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 1.08e-02 params: [0.45947844 0.53860235 0.30927166]\n",
      "Epoch [400/6000] Loss: 4.96e-03 params: [0.28009066 0.75177723 0.5590946 ]\n",
      "Epoch [600/6000] Loss: 3.87e-03 params: [0.19658825 0.8368631  0.7521486 ]\n",
      "Epoch [800/6000] Loss: 3.64e-03 params: [0.15753292 0.8408513  0.909965  ]\n",
      "Epoch [1000/6000] Loss: 3.39e-03 params: [0.12089282 0.838424   1.0637769 ]\n",
      "Epoch [1200/6000] Loss: 3.17e-03 params: [0.0865568 0.837476  1.2154157]\n",
      "Epoch [1400/6000] Loss: 2.96e-03 params: [0.05803441 0.83744305 1.3637774 ]\n",
      "Epoch [1600/6000] Loss: 2.87e-03 params: [0.0353985 0.8364472 1.5064253]\n",
      "Epoch 01775: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1800/6000] Loss: 2.83e-03 params: [0.0168425 0.8347883 1.6338304]\n",
      "Epoch [2000/6000] Loss: 2.80e-03 params: [0.0074019 0.8329881 1.6996857]\n",
      "Epoch [2200/6000] Loss: 2.78e-03 params: [8.606814e-06 8.316971e-01 1.765621e+00]\n",
      "Epoch [2400/6000] Loss: 2.77e-03 params: [6.8779691e-06 8.3143604e-01 1.8319025e+00]\n",
      "Epoch [2600/6000] Loss: 2.75e-03 params: [1.30356875e-05 8.31279874e-01 1.89827168e+00]\n",
      "Epoch [2800/6000] Loss: 2.74e-03 params: [8.1697613e-07 8.3112961e-01 1.9644036e+00]\n",
      "Epoch [3000/6000] Loss: 2.73e-03 params: [2.5438162e-06 8.3098501e-01 2.0300152e+00]\n",
      "Epoch [3200/6000] Loss: 2.72e-03 params: [9.0437516e-06 8.3084804e-01 2.0948339e+00]\n",
      "Epoch [3400/6000] Loss: 2.71e-03 params: [5.7804546e-06 8.3071887e-01 2.1585536e+00]\n",
      "Epoch [3600/6000] Loss: 2.70e-03 params: [4.9159071e-06 8.3061957e-01 2.2209835e+00]\n",
      "Epoch 03773: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [3800/6000] Loss: 2.69e-03 params: [3.1319353e-06 8.3070213e-01 2.2780128e+00]\n",
      "Epoch [4000/6000] Loss: 2.68e-03 params: [1.4702412e-06 8.3041424e-01 2.3083463e+00]\n",
      "Epoch [4200/6000] Loss: 2.68e-03 params: [1.5946584e-06 8.3033884e-01 2.3391154e+00]\n",
      "Epoch [4400/6000] Loss: 2.67e-03 params: [1.7146215e-06 8.3027208e-01 2.3701103e+00]\n",
      "Epoch [4600/6000] Loss: 2.67e-03 params: [4.4996750e-07 8.3020753e-01 2.4011924e+00]\n",
      "Epoch [4800/6000] Loss: 2.67e-03 params: [9.5394753e-06 8.3014625e-01 2.4321954e+00]\n",
      "Epoch [5000/6000] Loss: 2.66e-03 params: [6.5277345e-06 8.3008987e-01 2.4629869e+00]\n",
      "Epoch [5200/6000] Loss: 2.65e-03 params: [8.0546943e-06 8.3004034e-01 2.4934199e+00]\n",
      "Epoch [5400/6000] Loss: 2.65e-03 params: [7.0857927e-06 8.3003908e-01 2.5233433e+00]\n",
      "Epoch [5600/6000] Loss: 2.70e-03 params: [6.7885449e-06 8.3000368e-01 2.5526469e+00]\n",
      "Epoch [5800/6000] Loss: 2.64e-03 params: [7.4452946e-06 8.2992542e-01 2.5811772e+00]\n",
      "Epoch [6000/6000] Loss: 2.63e-03 params: [5.5031528e-06 8.2989383e-01 2.6088068e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# G_5, cGEM=12.5\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 12.5])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/G_5.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e7aac84-040b-4c36-bf00-6f577ee7844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=5.503153e-06\n",
      "fm=0.8298938\n",
      "fp=2.6088068\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8a4c58e-2905-4503-9f99-7e27f6367ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 3.65e-02 params: [6.1462415e-06 4.8797887e-02 5.0217044e-01]\n",
      "Epoch [400/6000] Loss: 2.66e-02 params: [2.1042334e-04 1.1982346e-01 5.6850272e-01]\n",
      "Epoch [600/6000] Loss: 2.39e-02 params: [4.8872156e-05 2.2880015e-01 6.7441577e-01]\n",
      "Epoch [800/6000] Loss: 2.01e-02 params: [6.404288e-05 3.876549e-01 8.344604e-01]\n",
      "Epoch [1000/6000] Loss: 1.28e-02 params: [1.8519958e-04 6.1164606e-01 1.0722606e+00]\n",
      "Epoch [1200/6000] Loss: 5.59e-03 params: [9.4082134e-07 8.2833058e-01 1.3383409e+00]\n",
      "Epoch [1400/6000] Loss: 4.85e-03 params: [2.1424288e-05 8.8694662e-01 1.4961666e+00]\n",
      "Epoch [1600/6000] Loss: 4.77e-03 params: [1.267912e-05 8.910900e-01 1.613017e+00]\n",
      "Epoch [1800/6000] Loss: 4.69e-03 params: [1.0393574e-05 8.9110458e-01 1.7240778e+00]\n",
      "Epoch [2000/6000] Loss: 4.61e-03 params: [3.2858967e-05 8.9103109e-01 1.8310319e+00]\n",
      "Epoch 02105: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [2200/6000] Loss: 4.57e-03 params: [1.061211e-05 8.910243e-01 1.909849e+00]\n",
      "Epoch [2400/6000] Loss: 4.54e-03 params: [1.6564804e-06 8.9093083e-01 1.9613271e+00]\n",
      "Epoch [2600/6000] Loss: 4.50e-03 params: [1.7840632e-05 8.9088815e-01 2.0132892e+00]\n",
      "Epoch [2800/6000] Loss: 4.47e-03 params: [1.4110354e-05 8.9089406e-01 2.0654411e+00]\n",
      "Epoch [3000/6000] Loss: 4.43e-03 params: [1.8165538e-06 8.9094049e-01 2.1175361e+00]\n",
      "Epoch [3200/6000] Loss: 4.40e-03 params: [2.2288637e-05 8.9103085e-01 2.1694174e+00]\n",
      "Epoch [3400/6000] Loss: 4.36e-03 params: [1.7895749e-05 8.9117187e-01 2.2209964e+00]\n",
      "Epoch [3600/6000] Loss: 4.33e-03 params: [9.7563116e-06 8.9140159e-01 2.2722542e+00]\n",
      "Epoch [3800/6000] Loss: 4.29e-03 params: [1.6184769e-05 8.9161462e-01 2.3230898e+00]\n",
      "Epoch [4000/6000] Loss: 4.26e-03 params: [2.7995055e-05 8.9189667e-01 2.3735280e+00]\n",
      "Epoch [4200/6000] Loss: 4.24e-03 params: [5.5620876e-06 8.9221054e-01 2.4234035e+00]\n",
      "Epoch [4400/6000] Loss: 4.57e-03 params: [7.954713e-05 8.924373e-01 2.472357e+00]\n",
      "Epoch [4600/6000] Loss: 4.19e-03 params: [2.9827679e-05 8.9266515e-01 2.5199914e+00]\n",
      "Epoch [4800/6000] Loss: 4.18e-03 params: [2.6061045e-05 8.9283782e-01 2.5656946e+00]\n",
      "Epoch [5000/6000] Loss: 4.16e-03 params: [1.2970642e-05 8.9303213e-01 2.6088161e+00]\n",
      "Epoch [5200/6000] Loss: 4.15e-03 params: [9.9007630e-06 8.9297116e-01 2.6484454e+00]\n",
      "Epoch [5400/6000] Loss: 4.14e-03 params: [4.5744255e-06 8.9296108e-01 2.6841927e+00]\n",
      "Epoch 05575: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [5600/6000] Loss: 4.13e-03 params: [2.3333127e-05 8.9304763e-01 2.7138095e+00]\n",
      "Epoch [5800/6000] Loss: 4.12e-03 params: [2.5511094e-05 8.9289522e-01 2.7280378e+00]\n",
      "Epoch [6000/6000] Loss: 4.12e-03 params: [2.6773840e-05 8.9286816e-01 2.7416446e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# H_5, cGEM=12.5\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 12.5])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/H_5.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99ac7fc0-bd88-4236-9fe2-3b26ce02a04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=2.677384e-05\n",
      "fm=0.89286816\n",
      "fp=2.7416446\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7102b1b9-b673-41fd-bb9b-ccac99b29785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 2.60e-01 params: [0.01278264 0.41723514 0.8060002 ]\n",
      "Epoch [400/6000] Loss: 1.40e-01 params: [2.4258377e-04 7.1132392e-01 1.1124709e+00]\n",
      "Epoch [600/6000] Loss: 4.66e-02 params: [5.9364131e-05 9.5390016e-01 1.4157515e+00]\n",
      "Epoch [800/6000] Loss: 4.00e-02 params: [2.7057071e-05 1.0068508e+00 1.6050955e+00]\n",
      "Epoch [1000/6000] Loss: 3.91e-02 params: [6.9639086e-06 1.0100096e+00 1.7678770e+00]\n",
      "Epoch [1200/6000] Loss: 3.84e-02 params: [7.2510356e-06 1.0094671e+00 1.9289615e+00]\n",
      "Epoch [1400/6000] Loss: 3.79e-02 params: [9.2229393e-06 1.0087794e+00 2.0885849e+00]\n",
      "Epoch [1600/6000] Loss: 3.77e-02 params: [9.7063376e-06 1.0080571e+00 2.2456865e+00]\n",
      "Epoch [1800/6000] Loss: 3.69e-02 params: [1.1692493e-05 1.0073761e+00 2.3996389e+00]\n",
      "Epoch [2000/6000] Loss: 3.65e-02 params: [1.0708550e-05 1.0067148e+00 2.5499184e+00]\n",
      "Epoch [2200/6000] Loss: 3.62e-02 params: [1.1031559e-05 1.0060965e+00 2.6961658e+00]\n",
      "Epoch [2400/6000] Loss: 3.58e-02 params: [1.1596514e-05 1.0054555e+00 2.8380280e+00]\n",
      "Epoch [2600/6000] Loss: 3.55e-02 params: [1.08314825e-05 1.00485742e+00 2.97535539e+00]\n",
      "Epoch [2800/6000] Loss: 3.52e-02 params: [1.8079962e-05 1.0042850e+00 3.1078672e+00]\n",
      "Epoch [3000/6000] Loss: 3.80e-02 params: [1.5306292e-05 1.0037506e+00 3.2352395e+00]\n",
      "Epoch [3200/6000] Loss: 3.47e-02 params: [1.0094774e-04 1.0032376e+00 3.3572714e+00]\n",
      "Epoch [3400/6000] Loss: 3.45e-02 params: [6.9682370e-05 1.0027583e+00 3.4736214e+00]\n",
      "Epoch [3600/6000] Loss: 3.78e-02 params: [8.2374230e-05 1.0023199e+00 3.5838609e+00]\n",
      "Epoch [3800/6000] Loss: 3.42e-02 params: [6.1243991e-05 1.0019128e+00 3.6876402e+00]\n",
      "Epoch [4000/6000] Loss: 3.40e-02 params: [3.6643680e-05 1.0015466e+00 3.7844498e+00]\n",
      "Epoch [4200/6000] Loss: 3.38e-02 params: [2.6805810e-05 1.0012873e+00 3.8735628e+00]\n",
      "Epoch [4400/6000] Loss: 3.34e-02 params: [5.7804398e-05 1.0011688e+00 3.9543998e+00]\n",
      "Epoch [4600/6000] Loss: 3.27e-02 params: [1.1430162e-05 1.0013169e+00 4.0262127e+00]\n",
      "Epoch [4800/6000] Loss: 3.20e-02 params: [3.5265544e-05 1.0015726e+00 4.0885715e+00]\n",
      "Epoch [5000/6000] Loss: 3.14e-02 params: [1.28024985e-05 1.00158870e+00 4.14162588e+00]\n",
      "Epoch [5200/6000] Loss: 3.10e-02 params: [5.4433855e-05 1.0013790e+00 4.1852951e+00]\n",
      "Epoch [5400/6000] Loss: 3.08e-02 params: [2.6349910e-05 1.0011599e+00 4.2199469e+00]\n",
      "Epoch [5600/6000] Loss: 3.07e-02 params: [1.7783231e-04 1.0009505e+00 4.2467685e+00]\n",
      "Epoch [5800/6000] Loss: 3.06e-02 params: [2.7661001e-05 1.0008432e+00 4.2666965e+00]\n",
      "Epoch [6000/6000] Loss: 3.11e-02 params: [3.340596e-05 1.000728e+00 4.280553e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# E_6, cGEM=25\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 25])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/E_6.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bae7524-5a77-42d9-89fe-46721eb37dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=3.340596e-05\n",
      "fm=1.000728\n",
      "fp=4.280553\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc1538e0-c511-48eb-be0c-5fb08a1fac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 2.04e-01 params: [0.51530486 0.6002498  1.1199065 ]\n",
      "Epoch [400/6000] Loss: 6.73e-02 params: [0.3161297 0.8599209 1.4006827]\n",
      "Epoch [600/6000] Loss: 2.83e-02 params: [0.21934637 0.993567   1.6211469 ]\n",
      "Epoch [800/6000] Loss: 2.67e-02 params: [0.18380126 1.0116632  1.7782108 ]\n",
      "Epoch [1000/6000] Loss: 2.61e-02 params: [0.15390912 1.0114783  1.9289938 ]\n",
      "Epoch [1200/6000] Loss: 2.56e-02 params: [0.12074645 1.0102053  2.0802126 ]\n",
      "Epoch [1400/6000] Loss: 2.51e-02 params: [0.08388893 1.0088958  2.230506  ]\n",
      "Epoch [1600/6000] Loss: 2.46e-02 params: [0.04344428 1.0075082  2.378536  ]\n",
      "Epoch [1800/6000] Loss: 2.43e-02 params: [4.0323375e-04 1.0060824e+00 2.5233657e+00]\n",
      "Epoch [2000/6000] Loss: 2.40e-02 params: [7.9078789e-05 1.0053581e+00 2.6649404e+00]\n",
      "Epoch [2200/6000] Loss: 2.37e-02 params: [7.0804774e-05 1.0046997e+00 2.8029888e+00]\n",
      "Epoch [2400/6000] Loss: 2.35e-02 params: [8.6578730e-06 1.0040834e+00 2.9370563e+00]\n",
      "Epoch [2600/6000] Loss: 2.34e-02 params: [5.5202487e-05 1.0035622e+00 3.0667334e+00]\n",
      "Epoch [2800/6000] Loss: 2.32e-02 params: [1.4678208e-06 1.0029194e+00 3.1915598e+00]\n",
      "Epoch [3000/6000] Loss: 2.31e-02 params: [2.8970788e-05 1.0023685e+00 3.3112335e+00]\n",
      "Epoch 03160: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [3200/6000] Loss: 2.30e-02 params: [2.9793624e-05 1.0019512e+00 3.4144931e+00]\n",
      "Epoch [3400/6000] Loss: 2.30e-02 params: [2.6893846e-05 1.0016392e+00 3.4707801e+00]\n",
      "Epoch [3600/6000] Loss: 2.29e-02 params: [1.7798378e-05 1.0013860e+00 3.5272627e+00]\n",
      "Epoch [3800/6000] Loss: 2.28e-02 params: [3.2104548e-05 1.0011315e+00 3.5836163e+00]\n",
      "Epoch [4000/6000] Loss: 2.28e-02 params: [2.6771719e-05 1.0008771e+00 3.6395459e+00]\n",
      "Epoch [4200/6000] Loss: 2.27e-02 params: [2.7291153e-05 1.0006236e+00 3.6947618e+00]\n",
      "Epoch [4400/6000] Loss: 2.27e-02 params: [3.3261182e-05 1.0003707e+00 3.7489803e+00]\n",
      "Epoch [4600/6000] Loss: 2.26e-02 params: [3.8416380e-05 1.0001158e+00 3.8019218e+00]\n",
      "Epoch [4800/6000] Loss: 2.26e-02 params: [5.2553038e-05 9.9986219e-01 3.8533099e+00]\n",
      "Epoch [5000/6000] Loss: 2.25e-02 params: [4.9499358e-06 9.9961019e-01 3.9028811e+00]\n",
      "Epoch [5200/6000] Loss: 2.24e-02 params: [7.0016013e-06 9.9936283e-01 3.9503901e+00]\n",
      "Epoch [5400/6000] Loss: 2.26e-02 params: [7.6560718e-06 9.9914515e-01 3.9956009e+00]\n",
      "Epoch [5600/6000] Loss: 2.23e-02 params: [1.1111473e-05 9.9888134e-01 4.0382962e+00]\n",
      "Epoch [5800/6000] Loss: 2.22e-02 params: [1.3996287e-05 9.9864167e-01 4.0783372e+00]\n",
      "Epoch [6000/6000] Loss: 2.22e-02 params: [1.6821685e-05 9.9840051e-01 4.1156373e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# F_6, cGEM=25\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 25])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/F_6.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a70ef9ef-c246-43c8-9850-98459dbcbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=1.6821685e-05\n",
      "fm=0.9984005\n",
      "fp=4.1156373\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b39834a-0660-4d98-9931-bfe87c45b6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 2.20e-01 params: [0.77453655 0.545974   0.30683607]\n",
      "Epoch [400/6000] Loss: 9.12e-02 params: [0.5610074  0.8168991  0.60084724]\n",
      "Epoch [600/6000] Loss: 3.28e-02 params: [0.43990174 0.98672044 0.86178017]\n",
      "Epoch [800/6000] Loss: 2.93e-02 params: [0.39535668 1.0137042  1.0483978 ]\n",
      "Epoch [1000/6000] Loss: 3.08e-02 params: [0.36033812 1.0136328  1.2223904 ]\n",
      "Epoch [1200/6000] Loss: 2.77e-02 params: [0.32181305 1.011876   1.3945488 ]\n",
      "Epoch [1400/6000] Loss: 2.71e-02 params: [0.2790204 1.0100943 1.5645015]\n",
      "Epoch [1600/6000] Loss: 2.65e-02 params: [0.23206022 1.0082338  1.7316097 ]\n",
      "Epoch [1800/6000] Loss: 2.59e-02 params: [0.18100232 1.0063639  1.8955582 ]\n",
      "Epoch [2000/6000] Loss: 2.54e-02 params: [0.12598056 1.0044143  2.0560303 ]\n",
      "Epoch [2200/6000] Loss: 2.48e-02 params: [0.06705938 1.00246    2.2128415 ]\n",
      "Epoch [2400/6000] Loss: 2.42e-02 params: [0.00427518 1.0005296  2.3657653 ]\n",
      "Epoch [2600/6000] Loss: 2.35e-02 params: [1.2642919e-05 9.9993318e-01 2.5154197e+00]\n",
      "Epoch [2800/6000] Loss: 2.29e-02 params: [3.3985954e-05 9.9977857e-01 2.6624959e+00]\n",
      "Epoch [3000/6000] Loss: 2.25e-02 params: [2.2482196e-05 9.9956709e-01 2.8071027e+00]\n",
      "Epoch [3200/6000] Loss: 2.22e-02 params: [2.1662423e-05 9.9913478e-01 2.9489374e+00]\n",
      "Epoch [3400/6000] Loss: 2.20e-02 params: [1.7539511e-05 9.9860495e-01 3.0875590e+00]\n",
      "Epoch [3600/6000] Loss: 2.18e-02 params: [6.1826919e-05 9.9788630e-01 3.2226539e+00]\n",
      "Epoch [3800/6000] Loss: 2.16e-02 params: [3.7465052e-06 9.9720591e-01 3.3539968e+00]\n",
      "Epoch [4000/6000] Loss: 2.14e-02 params: [1.3857876e-05 9.9653602e-01 3.4815695e+00]\n",
      "Epoch [4200/6000] Loss: 2.13e-02 params: [7.5661519e-05 9.9590766e-01 3.6050358e+00]\n",
      "Epoch [4400/6000] Loss: 2.12e-02 params: [1.2894843e-05 9.9530220e-01 3.7237217e+00]\n",
      "Epoch 04525: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [4600/6000] Loss: 2.11e-02 params: [5.3814296e-05 9.9482870e-01 3.8166733e+00]\n",
      "Epoch [4800/6000] Loss: 2.11e-02 params: [5.7848192e-05 9.9453545e-01 3.8732224e+00]\n",
      "Epoch [5000/6000] Loss: 2.10e-02 params: [6.1750245e-05 9.9424171e-01 3.9299471e+00]\n",
      "Epoch [5200/6000] Loss: 2.10e-02 params: [6.540687e-05 9.939484e-01 3.986543e+00]\n",
      "Epoch [5400/6000] Loss: 2.09e-02 params: [6.8778325e-05 9.9365658e-01 4.0427113e+00]\n",
      "Epoch [5600/6000] Loss: 2.09e-02 params: [7.1863244e-05 9.9336755e-01 4.0981598e+00]\n",
      "Epoch [5800/6000] Loss: 2.09e-02 params: [7.472824e-05 9.930826e-01 4.152599e+00]\n",
      "Epoch [6000/6000] Loss: 2.08e-02 params: [1.4426978e-05 9.9280643e-01 4.2057157e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# G_6, cGEM=25\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 25])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/G_6.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bd5574f-eae7-427e-ac2d-ef98eb375f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=1.4426978e-05\n",
      "fm=0.99280643\n",
      "fp=4.2057157\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b676e074-6607-40a4-8d88-40c9663b2d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 4.04e-02 params: [0.74051964 1.0297912  0.8811191 ]\n",
      "Epoch [400/6000] Loss: 3.23e-02 params: [0.6556907 1.0348219 1.0631082]\n",
      "Epoch [600/6000] Loss: 3.02e-02 params: [0.55690366 1.0322517  1.2419655 ]\n",
      "Epoch [800/6000] Loss: 2.88e-02 params: [0.44598487 1.0297877  1.4186814 ]\n",
      "Epoch [1000/6000] Loss: 2.73e-02 params: [0.32748926 1.0275143  1.5924528 ]\n",
      "Epoch [1200/6000] Loss: 2.61e-02 params: [0.20496878 1.0252448  1.7624133 ]\n",
      "Epoch [1400/6000] Loss: 2.52e-02 params: [0.08042047 1.0228736  1.927939  ]\n",
      "Epoch [1600/6000] Loss: 2.45e-02 params: [8.7480075e-05 1.0207733e+00 2.0887012e+00]\n",
      "Epoch [1800/6000] Loss: 2.40e-02 params: [2.2080530e-05 1.0201137e+00 2.2461174e+00]\n",
      "Epoch [2000/6000] Loss: 2.36e-02 params: [9.3788396e-05 1.0192676e+00 2.4003820e+00]\n",
      "Epoch [2200/6000] Loss: 2.31e-02 params: [2.1679562e-05 1.0186949e+00 2.5512908e+00]\n",
      "Epoch [2400/6000] Loss: 2.27e-02 params: [1.1138502e-04 1.0180495e+00 2.6985226e+00]\n",
      "Epoch [2600/6000] Loss: 2.24e-02 params: [2.0422738e-05 1.0175840e+00 2.8420129e+00]\n",
      "Epoch [2800/6000] Loss: 2.21e-02 params: [1.0240608e-04 1.0170642e+00 2.9813838e+00]\n",
      "Epoch [3000/6000] Loss: 2.19e-02 params: [4.6954428e-05 1.0165259e+00 3.1163623e+00]\n",
      "Epoch [3200/6000] Loss: 2.17e-02 params: [1.0614150e-04 1.0161079e+00 3.2465761e+00]\n",
      "Epoch 03285: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [3400/6000] Loss: 2.16e-02 params: [3.1572981e-05 1.0157077e+00 3.3368173e+00]\n",
      "Epoch [3600/6000] Loss: 2.15e-02 params: [4.4876986e-05 1.0155081e+00 3.3999810e+00]\n",
      "Epoch [3800/6000] Loss: 2.14e-02 params: [3.1563821e-05 1.0152856e+00 3.4634185e+00]\n",
      "Epoch [4000/6000] Loss: 2.13e-02 params: [7.6790820e-07 1.0150573e+00 3.5268788e+00]\n",
      "Epoch [4200/6000] Loss: 2.12e-02 params: [5.1458439e-05 1.0148267e+00 3.5901237e+00]\n",
      "Epoch [4400/6000] Loss: 2.12e-02 params: [1.1878801e-06 1.0145937e+00 3.6529365e+00]\n",
      "Epoch [4600/6000] Loss: 2.21e-02 params: [5.1904870e-05 1.0143605e+00 3.7151201e+00]\n",
      "Epoch [4800/6000] Loss: 2.10e-02 params: [5.9632606e-05 1.0141140e+00 3.7764812e+00]\n",
      "Epoch [5000/6000] Loss: 2.10e-02 params: [8.1721468e-05 1.0138682e+00 3.8368180e+00]\n",
      "Epoch [5200/6000] Loss: 2.09e-02 params: [4.8439975e-05 1.0136231e+00 3.8959296e+00]\n",
      "Epoch [5400/6000] Loss: 2.09e-02 params: [3.7593498e-05 1.0134130e+00 3.9535959e+00]\n",
      "Epoch [5600/6000] Loss: 2.08e-02 params: [6.0936800e-05 1.0131882e+00 4.0096097e+00]\n",
      "Epoch 05759: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [5800/6000] Loss: 2.08e-02 params: [6.9285743e-06 1.0129886e+00 4.0584154e+00]\n",
      "Epoch [6000/6000] Loss: 2.08e-02 params: [2.6213222e-05 1.0128875e+00 4.0853634e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# H_6, cGEM=25\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 25])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/H_6.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52c093c8-95e6-433d-85f2-505649249c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=2.6213222e-05\n",
      "fm=1.0128875\n",
      "fp=4.0853634\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "643f3eae-9156-493b-8041-99abaaddf3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 7.28e-02 params: [0.37199715 0.5609745  0.26468846]\n",
      "Epoch [400/6000] Loss: 4.21e-02 params: [0.16966021 0.79411334 0.5210064 ]\n",
      "Epoch [600/6000] Loss: 2.38e-02 params: [0.02390854 0.9882431  0.80396706]\n",
      "Epoch [800/6000] Loss: 2.18e-02 params: [1.0483855e-04 1.0448000e+00 1.0276024e+00]\n",
      "Epoch [1000/6000] Loss: 2.13e-02 params: [2.3958357e-05 1.0515875e+00 1.2270241e+00]\n",
      "Epoch [1200/6000] Loss: 2.09e-02 params: [1.7350518e-05 1.0513569e+00 1.4207941e+00]\n",
      "Epoch [1400/6000] Loss: 2.03e-02 params: [2.5832238e-05 1.0505730e+00 1.6117036e+00]\n",
      "Epoch [1600/6000] Loss: 1.98e-02 params: [2.0126568e-05 1.0498182e+00 1.8003110e+00]\n",
      "Epoch [1800/6000] Loss: 1.94e-02 params: [3.5414992e-05 1.0490968e+00 1.9869401e+00]\n",
      "Epoch [2000/6000] Loss: 1.91e-02 params: [4.2215881e-05 1.0482562e+00 2.1717470e+00]\n",
      "Epoch [2200/6000] Loss: 1.88e-02 params: [1.2055782e-04 1.0474027e+00 2.3547704e+00]\n",
      "Epoch [2400/6000] Loss: 1.86e-02 params: [1.0352135e-04 1.0465649e+00 2.5360258e+00]\n",
      "Epoch [2600/6000] Loss: 1.84e-02 params: [4.4291482e-07 1.0456563e+00 2.7155352e+00]\n",
      "Epoch [2800/6000] Loss: 1.82e-02 params: [7.9004756e-05 1.0447847e+00 2.8933318e+00]\n",
      "Epoch [3000/6000] Loss: 1.81e-02 params: [1.4837833e-04 1.0439496e+00 3.0694177e+00]\n",
      "Epoch [3200/6000] Loss: 1.79e-02 params: [1.4848493e-04 1.0430826e+00 3.2438357e+00]\n",
      "Epoch [3400/6000] Loss: 1.78e-02 params: [4.4822180e-05 1.0422343e+00 3.4165492e+00]\n",
      "Epoch [3600/6000] Loss: 2.16e-02 params: [3.0085403e-05 1.0414283e+00 3.5876303e+00]\n",
      "Epoch [3800/6000] Loss: 1.75e-02 params: [6.4730863e-05 1.0406008e+00 3.7570145e+00]\n",
      "Epoch [4000/6000] Loss: 1.74e-02 params: [8.0354730e-05 1.0398344e+00 3.9247627e+00]\n",
      "Epoch [4200/6000] Loss: 1.73e-02 params: [1.1395082e-04 1.0389999e+00 4.0907173e+00]\n",
      "Epoch [4400/6000] Loss: 1.72e-02 params: [6.6204360e-05 1.0382344e+00 4.2549500e+00]\n",
      "Epoch [4600/6000] Loss: 1.71e-02 params: [3.1446829e-04 1.0374705e+00 4.4173288e+00]\n",
      "Epoch [4800/6000] Loss: 1.70e-02 params: [1.2869634e-05 1.0367082e+00 4.5778656e+00]\n",
      "Epoch 04869: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [5000/6000] Loss: 1.70e-02 params: [5.5415225e-05 1.0361918e+00 4.6853499e+00]\n",
      "Epoch [5200/6000] Loss: 1.69e-02 params: [4.5205772e-05 1.0358188e+00 4.7657123e+00]\n",
      "Epoch [5400/6000] Loss: 1.69e-02 params: [3.9825958e-05 1.0354366e+00 4.8467617e+00]\n",
      "Epoch [5600/6000] Loss: 1.68e-02 params: [5.2263844e-05 1.0350485e+00 4.9283400e+00]\n",
      "Epoch [5800/6000] Loss: 1.68e-02 params: [4.1624859e-05 1.0346568e+00 5.0103106e+00]\n",
      "Epoch [6000/6000] Loss: 1.68e-02 params: [4.723844e-05 1.034263e+00 5.092544e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# E_7, cGEM=50\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 50])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/E_7.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "666ac280-ef33-4ba8-b1b6-dd263697585a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=4.723844e-05\n",
      "fm=1.034263\n",
      "fp=5.092544\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2ca6ae2-0af2-4194-9c9e-4dd2963e19b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 1.48e-01 params: [0.5316796  0.31286627 0.87604994]\n",
      "Epoch [400/6000] Loss: 1.24e-01 params: [0.3182947  0.49311498 1.0572278 ]\n",
      "Epoch [600/6000] Loss: 7.44e-02 params: [0.10442103 0.77763855 1.3702241 ]\n",
      "Epoch [800/6000] Loss: 3.82e-02 params: [3.5585286e-05 1.0070928e+00 1.7060941e+00]\n",
      "Epoch [1000/6000] Loss: 3.57e-02 params: [2.4566571e-05 1.0570539e+00 1.9437615e+00]\n",
      "Epoch [1200/6000] Loss: 3.53e-02 params: [1.1321914e-05 1.0607886e+00 2.1500318e+00]\n",
      "Epoch [1400/6000] Loss: 3.49e-02 params: [5.2392905e-05 1.0601507e+00 2.3478153e+00]\n",
      "Epoch [1600/6000] Loss: 3.45e-02 params: [1.9275463e-05 1.0592864e+00 2.5402946e+00]\n",
      "Epoch [1800/6000] Loss: 3.42e-02 params: [2.1183685e-05 1.0583823e+00 2.7284584e+00]\n",
      "Epoch [2000/6000] Loss: 3.38e-02 params: [1.9780091e-06 1.0575180e+00 2.9129999e+00]\n",
      "Epoch [2200/6000] Loss: 3.38e-02 params: [4.8693157e-05 1.0566734e+00 3.0943327e+00]\n",
      "Epoch [2400/6000] Loss: 3.32e-02 params: [3.2605236e-05 1.0558378e+00 3.2727342e+00]\n",
      "Epoch [2600/6000] Loss: 3.28e-02 params: [3.2729473e-05 1.0550302e+00 3.4484868e+00]\n",
      "Epoch [2800/6000] Loss: 3.25e-02 params: [5.7448684e-05 1.0542901e+00 3.6217542e+00]\n",
      "Epoch [3000/6000] Loss: 3.27e-02 params: [1.3131350e-05 1.0535151e+00 3.7926373e+00]\n",
      "Epoch [3200/6000] Loss: 3.17e-02 params: [4.6375146e-05 1.0527948e+00 3.9613431e+00]\n",
      "Epoch [3400/6000] Loss: 3.14e-02 params: [9.7195516e-05 1.0520765e+00 4.1279469e+00]\n",
      "Epoch [3600/6000] Loss: 3.12e-02 params: [9.9992540e-05 1.0513337e+00 4.2924523e+00]\n",
      "Epoch [3800/6000] Loss: 3.10e-02 params: [3.8817361e-06 1.0506111e+00 4.4548039e+00]\n",
      "Epoch [4000/6000] Loss: 3.08e-02 params: [9.2790542e-05 1.0498121e+00 4.6147389e+00]\n",
      "Epoch [4200/6000] Loss: 3.06e-02 params: [2.8374598e-05 1.0490410e+00 4.7724414e+00]\n",
      "Epoch [4400/6000] Loss: 3.04e-02 params: [1.8462169e-05 1.0483181e+00 4.9277520e+00]\n",
      "Epoch [4600/6000] Loss: 3.02e-02 params: [7.5101772e-05 1.0475101e+00 5.0804906e+00]\n",
      "Epoch [4800/6000] Loss: 3.00e-02 params: [1.5174632e-05 1.0467421e+00 5.2306852e+00]\n",
      "Epoch [5000/6000] Loss: 2.99e-02 params: [1.9492186e-04 1.0460136e+00 5.3780136e+00]\n",
      "Epoch [5200/6000] Loss: 2.97e-02 params: [3.8361657e-05 1.0452428e+00 5.5221314e+00]\n",
      "Epoch [5400/6000] Loss: 2.96e-02 params: [1.2506825e-05 1.0445359e+00 5.6629229e+00]\n",
      "Epoch [5600/6000] Loss: 2.95e-02 params: [1.9387906e-05 1.0438477e+00 5.8000741e+00]\n",
      "Epoch [5800/6000] Loss: 2.94e-02 params: [1.3490688e-04 1.0432091e+00 5.9333067e+00]\n",
      "Epoch 05848: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [6000/6000] Loss: 2.94e-02 params: [2.4882749e-05 1.0428274e+00 6.0146546e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# F_7, cGEM=50\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 50])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/F_7.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56932aee-1ce6-4aac-aa8e-4a21a5c77ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=2.488275e-05\n",
      "fm=1.0428274\n",
      "fp=6.0146546\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f618c6c-d8ac-4a47-a9ac-3bea473ea1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 8.19e-02 params: [0.35152915 0.8225233  1.2050297 ]\n",
      "Epoch [400/6000] Loss: 4.27e-02 params: [0.19682695 1.0046039  1.44987   ]\n",
      "Epoch [600/6000] Loss: 3.89e-02 params: [0.1272147 1.058293  1.6486465]\n",
      "Epoch [800/6000] Loss: 3.78e-02 params: [0.07914238 1.0633522  1.830961  ]\n",
      "Epoch [1000/6000] Loss: 3.72e-02 params: [0.02827492 1.0619664  2.012127  ]\n",
      "Epoch [1200/6000] Loss: 3.67e-02 params: [3.0375259e-06 1.0603237e+00 2.1931117e+00]\n",
      "Epoch [1400/6000] Loss: 3.77e-02 params: [6.5480650e-05 1.0594738e+00 2.3738282e+00]\n",
      "Epoch [1600/6000] Loss: 3.59e-02 params: [6.2950727e-05 1.0587037e+00 2.5536737e+00]\n",
      "Epoch 01716: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1800/6000] Loss: 3.57e-02 params: [2.5516592e-06 1.0581396e+00 2.6955101e+00]\n",
      "Epoch [2000/6000] Loss: 3.55e-02 params: [3.6291603e-05 1.0576816e+00 2.7853630e+00]\n",
      "Epoch [2200/6000] Loss: 3.53e-02 params: [3.0007723e-05 1.0572524e+00 2.8756745e+00]\n",
      "Epoch [2400/6000] Loss: 3.51e-02 params: [3.1556119e-06 1.0568269e+00 2.9662807e+00]\n",
      "Epoch [2600/6000] Loss: 3.49e-02 params: [4.5429399e-05 1.0563987e+00 3.0570529e+00]\n",
      "Epoch [2800/6000] Loss: 3.47e-02 params: [3.7019665e-05 1.0559694e+00 3.1478903e+00]\n",
      "Epoch [3000/6000] Loss: 3.46e-02 params: [6.1590072e-07 1.0555471e+00 3.2387369e+00]\n",
      "Epoch [3200/6000] Loss: 3.44e-02 params: [3.1763717e-05 1.0551097e+00 3.3295283e+00]\n",
      "Epoch [3400/6000] Loss: 3.47e-02 params: [2.9642795e-05 1.0546343e+00 3.4202006e+00]\n",
      "Epoch [3600/6000] Loss: 3.41e-02 params: [4.7010974e-05 1.0541791e+00 3.5107365e+00]\n",
      "Epoch [3800/6000] Loss: 3.39e-02 params: [2.0167943e-05 1.0537207e+00 3.6010990e+00]\n",
      "Epoch [4000/6000] Loss: 3.37e-02 params: [1.0245996e-05 1.0532732e+00 3.6912591e+00]\n",
      "Epoch [4200/6000] Loss: 3.37e-02 params: [1.1308515e-05 1.0527960e+00 3.7811918e+00]\n",
      "Epoch [4400/6000] Loss: 3.34e-02 params: [1.7116101e-05 1.0523036e+00 3.8708930e+00]\n",
      "Epoch [4600/6000] Loss: 3.33e-02 params: [2.5316069e-05 1.0518252e+00 3.9603503e+00]\n",
      "Epoch [4800/6000] Loss: 3.31e-02 params: [8.3829582e-05 1.0513501e+00 4.0495386e+00]\n",
      "Epoch [5000/6000] Loss: 3.31e-02 params: [5.6916775e-05 1.0508952e+00 4.1384115e+00]\n",
      "Epoch [5200/6000] Loss: 3.29e-02 params: [4.4563574e-05 1.0504135e+00 4.2269893e+00]\n",
      "Epoch [5400/6000] Loss: 3.28e-02 params: [8.8772009e-05 1.0499547e+00 4.3152151e+00]\n",
      "Epoch [5600/6000] Loss: 3.27e-02 params: [2.5625861e-05 1.0495745e+00 4.4030676e+00]\n",
      "Epoch [5800/6000] Loss: 3.25e-02 params: [5.0731218e-05 1.0491028e+00 4.4905214e+00]\n",
      "Epoch [6000/6000] Loss: 3.24e-02 params: [1.0655858e-06 1.0486866e+00 4.5776043e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# G_7, cGEM=50\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 50])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/G_7.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68c87bad-4ae3-4c5a-88ee-8126991a0608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=1.0655858e-06\n",
      "fm=1.0486866\n",
      "fp=4.5776043\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "981161f6-b3b1-4d86-8897-ad7e18bb86bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 7.09e-02 params: [0.6704456  0.85951006 0.8380866 ]\n",
      "Epoch [400/6000] Loss: 3.04e-02 params: [0.5239458 1.0281659 1.0826951]\n",
      "Epoch [600/6000] Loss: 2.70e-02 params: [0.455565  1.0679847 1.2905052]\n",
      "Epoch [800/6000] Loss: 2.57e-02 params: [0.39881274 1.0694591  1.4847764 ]\n",
      "Epoch [1000/6000] Loss: 2.53e-02 params: [0.33593798 1.0678356  1.6757944 ]\n",
      "Epoch [1200/6000] Loss: 2.50e-02 params: [0.26635122 1.0658814  1.8641924 ]\n",
      "Epoch [1400/6000] Loss: 2.47e-02 params: [0.19073687 1.0637679  2.050245  ]\n",
      "Epoch [1600/6000] Loss: 2.47e-02 params: [0.10986291 1.061507   2.2341924 ]\n",
      "Epoch [1800/6000] Loss: 2.42e-02 params: [0.02428535 1.0591661  2.4156687 ]\n",
      "Epoch [2000/6000] Loss: 2.40e-02 params: [3.0850875e-05 1.0576987e+00 2.5952919e+00]\n",
      "Epoch 02142: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [2200/6000] Loss: 2.38e-02 params: [2.1255128e-06 1.0570240e+00 2.7482035e+00]\n",
      "Epoch [2400/6000] Loss: 2.37e-02 params: [4.1802923e-05 1.0565708e+00 2.8375311e+00]\n",
      "Epoch [2600/6000] Loss: 2.36e-02 params: [2.7292755e-05 1.0561517e+00 2.9273515e+00]\n",
      "Epoch [2800/6000] Loss: 2.35e-02 params: [2.8898263e-05 1.0557384e+00 3.0174758e+00]\n",
      "Epoch [3000/6000] Loss: 2.34e-02 params: [2.8561513e-05 1.0553247e+00 3.1077914e+00]\n",
      "Epoch [3200/6000] Loss: 2.33e-02 params: [5.0538620e-05 1.0549104e+00 3.1982176e+00]\n",
      "Epoch [3400/6000] Loss: 2.32e-02 params: [3.5472596e-05 1.0544962e+00 3.2886736e+00]\n",
      "Epoch [3600/6000] Loss: 2.31e-02 params: [4.2847074e-05 1.0540769e+00 3.3791053e+00]\n",
      "Epoch [3800/6000] Loss: 2.30e-02 params: [4.9361217e-05 1.0536693e+00 3.4694843e+00]\n",
      "Epoch [4000/6000] Loss: 2.61e-02 params: [1.9390136e-05 1.0532469e+00 3.5597715e+00]\n",
      "Epoch [4200/6000] Loss: 2.27e-02 params: [7.6091892e-06 1.0528320e+00 3.6499226e+00]\n",
      "Epoch [4400/6000] Loss: 2.26e-02 params: [2.9324192e-05 1.0524206e+00 3.7399297e+00]\n",
      "Epoch [4600/6000] Loss: 2.25e-02 params: [8.3466308e-05 1.0520297e+00 3.8297708e+00]\n",
      "Epoch [4800/6000] Loss: 2.25e-02 params: [5.0890776e-06 1.0516158e+00 3.9194391e+00]\n",
      "Epoch 04801: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [5000/6000] Loss: 2.24e-02 params: [1.5916023e-05 1.0514023e+00 3.9648316e+00]\n",
      "Epoch [5200/6000] Loss: 2.23e-02 params: [2.2717632e-06 1.0511985e+00 4.0101128e+00]\n",
      "Epoch [5400/6000] Loss: 2.22e-02 params: [1.7421316e-05 1.0509968e+00 4.0556774e+00]\n",
      "Epoch [5600/6000] Loss: 2.22e-02 params: [1.6395643e-05 1.0507957e+00 4.1014695e+00]\n",
      "Epoch [5800/6000] Loss: 2.21e-02 params: [2.5172540e-06 1.0505966e+00 4.1474547e+00]\n",
      "Epoch [6000/6000] Loss: 2.20e-02 params: [1.8087365e-05 1.0503994e+00 4.1935878e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# H_7, cGEM=50\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 50])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/H_7.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cad6e7eb-c529-474c-8998-9521414f2983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=1.8087365e-05\n",
      "fm=1.0503994\n",
      "fp=4.193588\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e18f934a-f59f-46e2-a307-1a433ce72564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 4.58e-02 params: [0.80533457 1.0338404  0.5343888 ]\n",
      "Epoch [400/6000] Loss: 4.22e-02 params: [0.6840686 1.1326264 0.7499276]\n",
      "Epoch [600/6000] Loss: 4.16e-02 params: [0.59175795 1.1461716  0.9468637 ]\n",
      "Epoch [800/6000] Loss: 4.11e-02 params: [0.49460718 1.1423727  1.1412038 ]\n",
      "Epoch [1000/6000] Loss: 4.08e-02 params: [0.38767305 1.1365101  1.3352242 ]\n",
      "Epoch [1200/6000] Loss: 4.05e-02 params: [0.27254376 1.1301467  1.5288769 ]\n",
      "Epoch [1400/6000] Loss: 4.03e-02 params: [0.15116332 1.1233045  1.7220223 ]\n",
      "Epoch [1600/6000] Loss: 4.00e-02 params: [0.02526294 1.1165154  1.9144752 ]\n",
      "Epoch [1800/6000] Loss: 3.98e-02 params: [1.0837401e-05 1.1135677e+00 2.1066046e+00]\n",
      "Epoch [2000/6000] Loss: 3.98e-02 params: [3.4303976e-05 1.1125925e+00 2.2986355e+00]\n",
      "Epoch 02003: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [2200/6000] Loss: 3.96e-02 params: [2.4935242e-05 1.1122041e+00 2.3966537e+00]\n",
      "Epoch [2400/6000] Loss: 3.95e-02 params: [2.0022177e-05 1.1117043e+00 2.4930353e+00]\n",
      "Epoch [2600/6000] Loss: 3.95e-02 params: [8.1559716e-05 1.1112822e+00 2.5896218e+00]\n",
      "Epoch [2800/6000] Loss: 3.94e-02 params: [1.5463749e-05 1.1108725e+00 2.6863523e+00]\n",
      "Epoch [3000/6000] Loss: 3.93e-02 params: [8.2018050e-06 1.1104516e+00 2.7831805e+00]\n",
      "Epoch [3200/6000] Loss: 3.93e-02 params: [1.1273780e-05 1.1100148e+00 2.8800821e+00]\n",
      "Epoch [3400/6000] Loss: 3.92e-02 params: [5.0790921e-05 1.1095891e+00 2.9770234e+00]\n",
      "Epoch [3600/6000] Loss: 3.91e-02 params: [4.0076564e-05 1.1090715e+00 3.0740004e+00]\n",
      "Epoch [3800/6000] Loss: 3.91e-02 params: [3.6007685e-05 1.1085778e+00 3.1709783e+00]\n",
      "Epoch [4000/6000] Loss: 3.90e-02 params: [1.2988632e-04 1.1081054e+00 3.2679529e+00]\n",
      "Epoch [4200/6000] Loss: 3.94e-02 params: [2.9841474e-05 1.1075966e+00 3.3649085e+00]\n",
      "Epoch [4400/6000] Loss: 3.88e-02 params: [4.2204818e-05 1.1071016e+00 3.4618447e+00]\n",
      "Epoch [4600/6000] Loss: 3.88e-02 params: [4.0666677e-05 1.1066236e+00 3.5587466e+00]\n",
      "Epoch [4800/6000] Loss: 3.87e-02 params: [3.9040831e-05 1.1061593e+00 3.6556194e+00]\n",
      "Epoch [5000/6000] Loss: 3.86e-02 params: [3.7603801e-05 1.1057128e+00 3.7524514e+00]\n",
      "Epoch [5200/6000] Loss: 3.86e-02 params: [3.6768841e-05 1.1052766e+00 3.8492386e+00]\n",
      "Epoch [5400/6000] Loss: 3.87e-02 params: [3.8260983e-05 1.1048505e+00 3.9459898e+00]\n",
      "Epoch [5600/6000] Loss: 3.84e-02 params: [3.5703957e-05 1.1044003e+00 4.0426903e+00]\n",
      "Epoch [5800/6000] Loss: 3.83e-02 params: [3.5385536e-05 1.1039863e+00 4.1393275e+00]\n",
      "Epoch 05925: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [6000/6000] Loss: 3.83e-02 params: [3.1229443e-05 1.1036727e+00 4.2180629e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# E_8, cGEM=100\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 100])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/E_8.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11780849-29f6-409d-8aac-c24a31d402e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=3.1229443e-05\n",
      "fm=1.1036727\n",
      "fp=4.218063\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dfca1d7-d3ef-4929-ac3c-02bcc50fa8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 1.17e-01 params: [0.3062629  0.41123444 0.34378684]\n",
      "Epoch [400/6000] Loss: 9.25e-02 params: [0.0932148 0.693674  0.6470136]\n",
      "Epoch [600/6000] Loss: 7.30e-02 params: [5.2534469e-05 9.4881201e-01 9.7098666e-01]\n",
      "Epoch [800/6000] Loss: 6.69e-02 params: [3.2159252e-05 1.0833205e+00 1.2493107e+00]\n",
      "Epoch [1000/6000] Loss: 6.59e-02 params: [1.07773385e-05 1.12114048e+00 1.48233485e+00]\n",
      "Epoch [1200/6000] Loss: 6.55e-02 params: [3.9134106e-06 1.1274571e+00 1.6980042e+00]\n",
      "Epoch [1400/6000] Loss: 6.52e-02 params: [7.6747310e-06 1.1275240e+00 1.9066929e+00]\n",
      "Epoch [1600/6000] Loss: 6.49e-02 params: [7.4950331e-06 1.1266627e+00 2.1112528e+00]\n",
      "Epoch [1800/6000] Loss: 6.47e-02 params: [7.4918818e-05 1.1257035e+00 2.3128216e+00]\n",
      "Epoch [2000/6000] Loss: 6.44e-02 params: [8.2767343e-05 1.1247522e+00 2.5120585e+00]\n",
      "Epoch [2200/6000] Loss: 6.41e-02 params: [1.4387340e-04 1.1236724e+00 2.7094104e+00]\n",
      "Epoch [2400/6000] Loss: 6.39e-02 params: [1.3834666e-05 1.1227016e+00 2.9051847e+00]\n",
      "Epoch [2600/6000] Loss: 6.37e-02 params: [3.4122946e-05 1.1218714e+00 3.0996473e+00]\n",
      "Epoch [2800/6000] Loss: 6.34e-02 params: [4.9746021e-05 1.1208452e+00 3.2928936e+00]\n",
      "Epoch [3000/6000] Loss: 6.32e-02 params: [5.3331325e-05 1.1200238e+00 3.4851470e+00]\n",
      "Epoch [3200/6000] Loss: 6.30e-02 params: [4.8739057e-05 1.1191646e+00 3.6765032e+00]\n",
      "Epoch [3400/6000] Loss: 6.28e-02 params: [2.7656113e-05 1.1183367e+00 3.8671060e+00]\n",
      "Epoch [3600/6000] Loss: 6.26e-02 params: [1.11916095e-04 1.11752796e+00 4.05704451e+00]\n",
      "Epoch [3800/6000] Loss: 6.24e-02 params: [1.2288523e-04 1.1167312e+00 4.2463622e+00]\n",
      "Epoch [4000/6000] Loss: 6.22e-02 params: [4.8231799e-05 1.1158170e+00 4.4350233e+00]\n",
      "Epoch [4200/6000] Loss: 6.20e-02 params: [2.0356519e-04 1.1149936e+00 4.6231360e+00]\n",
      "Epoch [4400/6000] Loss: 6.19e-02 params: [1.4758622e-04 1.1141274e+00 4.8106675e+00]\n",
      "Epoch [4600/6000] Loss: 6.17e-02 params: [1.5687069e-04 1.1132933e+00 4.9976449e+00]\n",
      "Epoch [4800/6000] Loss: 6.18e-02 params: [1.5376767e-04 1.1124309e+00 5.1840410e+00]\n",
      "Epoch [5000/6000] Loss: 6.19e-02 params: [2.4753547e-04 1.1116079e+00 5.3699088e+00]\n",
      "Epoch [5200/6000] Loss: 6.12e-02 params: [6.1496976e-05 1.1107438e+00 5.5552039e+00]\n",
      "Epoch [5400/6000] Loss: 6.11e-02 params: [4.8909133e-06 1.1099021e+00 5.7399521e+00]\n",
      "Epoch [5600/6000] Loss: 6.09e-02 params: [4.4727407e-05 1.1090549e+00 5.9241915e+00]\n",
      "Epoch [5800/6000] Loss: 6.08e-02 params: [7.4947595e-05 1.1082108e+00 6.1078825e+00]\n",
      "Epoch [6000/6000] Loss: 6.07e-02 params: [9.9825877e-05 1.1073649e+00 6.2910576e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# F_8, cGEM=100\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 100])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/F_8.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51496a01-d8a3-4d16-8e38-50cf4e5f774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=9.982588e-05\n",
      "fm=1.1073649\n",
      "fp=6.2910576\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bb65882-2431-4cad-bdaf-47acd68da728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 5.92e-02 params: [0.01467705 1.1065853  0.8402527 ]\n",
      "Epoch [400/6000] Loss: 5.57e-02 params: [1.7067880e-04 1.1184342e+00 1.0519190e+00]\n",
      "Epoch [600/6000] Loss: 5.49e-02 params: [1.2844204e-04 1.1183609e+00 1.2579942e+00]\n",
      "Epoch [800/6000] Loss: 5.46e-02 params: [2.4602386e-05 1.1179847e+00 1.4604605e+00]\n",
      "Epoch [1000/6000] Loss: 5.44e-02 params: [5.3640688e-05 1.1173435e+00 1.6604837e+00]\n",
      "Epoch [1200/6000] Loss: 5.42e-02 params: [1.0796789e-04 1.1162800e+00 1.8588300e+00]\n",
      "Epoch [1400/6000] Loss: 5.40e-02 params: [1.5854687e-04 1.1155119e+00 2.0557809e+00]\n",
      "Epoch [1600/6000] Loss: 5.38e-02 params: [3.8688224e-05 1.1146864e+00 2.2515926e+00]\n",
      "Epoch [1800/6000] Loss: 5.36e-02 params: [5.4094635e-06 1.1139449e+00 2.4464216e+00]\n",
      "Epoch [2000/6000] Loss: 5.43e-02 params: [1.1198459e-04 1.1129601e+00 2.6404362e+00]\n",
      "Epoch [2200/6000] Loss: 5.33e-02 params: [9.0629990e-05 1.1123018e+00 2.8335981e+00]\n",
      "Epoch [2400/6000] Loss: 5.31e-02 params: [3.2960204e-05 1.1115226e+00 3.0260158e+00]\n",
      "Epoch [2600/6000] Loss: 5.29e-02 params: [7.4064810e-06 1.1107945e+00 3.2177513e+00]\n",
      "Epoch [2800/6000] Loss: 5.29e-02 params: [1.0061714e-05 1.1102252e+00 3.4088750e+00]\n",
      "Epoch [3000/6000] Loss: 5.26e-02 params: [1.3663623e-05 1.1092784e+00 3.5993631e+00]\n",
      "Epoch [3200/6000] Loss: 5.27e-02 params: [3.5900928e-05 1.1087631e+00 3.7892590e+00]\n",
      "Epoch [3400/6000] Loss: 5.24e-02 params: [7.1301292e-06 1.1078402e+00 3.9785450e+00]\n",
      "Epoch [3600/6000] Loss: 5.24e-02 params: [3.4763354e-05 1.1063353e+00 4.1672368e+00]\n",
      "Epoch [3800/6000] Loss: 5.23e-02 params: [3.1218803e-04 1.1057277e+00 4.3553915e+00]\n",
      "Epoch [4000/6000] Loss: 5.20e-02 params: [3.1133892e-04 1.1050764e+00 4.5429211e+00]\n",
      "Epoch 04042: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [4200/6000] Loss: 5.17e-02 params: [4.5024051e-05 1.1044667e+00 4.6567359e+00]\n",
      "Epoch [4400/6000] Loss: 5.16e-02 params: [3.6172278e-06 1.1040465e+00 4.7507968e+00]\n",
      "Epoch [4600/6000] Loss: 5.15e-02 params: [1.1724856e-04 1.1036075e+00 4.8451729e+00]\n",
      "Epoch [4800/6000] Loss: 5.14e-02 params: [3.1258896e-05 1.1031669e+00 4.9397960e+00]\n",
      "Epoch [5000/6000] Loss: 5.13e-02 params: [1.2604953e-04 1.1027359e+00 5.0346208e+00]\n",
      "Epoch [5200/6000] Loss: 5.13e-02 params: [3.0858544e-05 1.1022959e+00 5.1295938e+00]\n",
      "Epoch [5400/6000] Loss: 5.12e-02 params: [6.0347771e-05 1.1018747e+00 5.2247038e+00]\n",
      "Epoch [5600/6000] Loss: 5.11e-02 params: [1.5290139e-05 1.1014653e+00 5.3199110e+00]\n",
      "Epoch [5800/6000] Loss: 5.13e-02 params: [8.5272201e-05 1.1008813e+00 5.4152007e+00]\n",
      "Epoch 05812: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [6000/6000] Loss: 5.10e-02 params: [1.1365548e-05 1.1008618e+00 5.4660335e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# G_8, cGEM=100\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 100])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/G_8.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "acd803d1-4001-4e04-aa9c-fb6a9c374d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=1.1365548e-05\n",
      "fm=1.1008618\n",
      "fp=5.4660335\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e79cbf94-a241-438c-b2d4-ff2b716f73a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 6.72e-02 params: [3.115518e-04 7.714279e-01 7.795229e-01]\n",
      "Epoch [400/6000] Loss: 5.07e-02 params: [1.3273529e-07 9.6009928e-01 1.0139719e+00]\n",
      "Epoch [600/6000] Loss: 4.62e-02 params: [1.3499008e-04 1.0776312e+00 1.2478522e+00]\n",
      "Epoch [800/6000] Loss: 4.55e-02 params: [2.6904481e-05 1.1160524e+00 1.4575315e+00]\n",
      "Epoch [1000/6000] Loss: 4.53e-02 params: [5.3923883e-05 1.1235467e+00 1.6574550e+00]\n",
      "Epoch [1200/6000] Loss: 4.50e-02 params: [1.0111622e-05 1.1240056e+00 1.8545651e+00]\n",
      "Epoch [1400/6000] Loss: 4.48e-02 params: [4.4728629e-05 1.1233829e+00 2.0504527e+00]\n",
      "Epoch [1600/6000] Loss: 4.46e-02 params: [1.07816995e-05 1.12264001e+00 2.24542952e+00]\n",
      "Epoch 01795: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1800/6000] Loss: 4.44e-02 params: [1.1441890e-05 1.1217194e+00 2.4377387e+00]\n",
      "Epoch [2000/6000] Loss: 4.43e-02 params: [2.5083376e-05 1.1214164e+00 2.5347388e+00]\n",
      "Epoch [2200/6000] Loss: 4.42e-02 params: [2.0912010e-05 1.1209447e+00 2.6318781e+00]\n",
      "Epoch [2400/6000] Loss: 4.41e-02 params: [3.4006232e-05 1.1205394e+00 2.7290871e+00]\n",
      "Epoch [2600/6000] Loss: 4.40e-02 params: [2.9866818e-05 1.1201758e+00 2.8263185e+00]\n",
      "Epoch [2800/6000] Loss: 4.39e-02 params: [2.4225215e-05 1.1198407e+00 2.9235933e+00]\n",
      "Epoch [3000/6000] Loss: 4.37e-02 params: [8.2349718e-05 1.1195397e+00 3.0208566e+00]\n",
      "Epoch [3200/6000] Loss: 4.46e-02 params: [2.2887587e-05 1.1192424e+00 3.1181033e+00]\n",
      "Epoch [3400/6000] Loss: 4.35e-02 params: [5.2449832e-05 1.1189287e+00 3.2153187e+00]\n",
      "Epoch [3600/6000] Loss: 4.34e-02 params: [2.6262849e-05 1.1186615e+00 3.3125207e+00]\n",
      "Epoch [3800/6000] Loss: 4.34e-02 params: [5.9392059e-06 1.1183236e+00 3.4096978e+00]\n",
      "Epoch [4000/6000] Loss: 4.33e-02 params: [3.1543994e-05 1.1180069e+00 3.5068302e+00]\n",
      "Epoch [4200/6000] Loss: 4.32e-02 params: [3.8699509e-05 1.1177065e+00 3.6039257e+00]\n",
      "Epoch [4400/6000] Loss: 4.31e-02 params: [2.7770242e-05 1.1174027e+00 3.7009785e+00]\n",
      "Epoch [4600/6000] Loss: 4.30e-02 params: [1.1875934e-06 1.1170803e+00 3.7979748e+00]\n",
      "Epoch [4800/6000] Loss: 4.30e-02 params: [7.1302580e-05 1.1166865e+00 3.8949225e+00]\n",
      "Epoch [5000/6000] Loss: 4.29e-02 params: [2.9045350e-06 1.1162914e+00 3.9917963e+00]\n",
      "Epoch [5200/6000] Loss: 4.28e-02 params: [1.1772911e-04 1.1159203e+00 4.0886102e+00]\n",
      "Epoch [5400/6000] Loss: 4.28e-02 params: [2.2618202e-05 1.1155528e+00 4.1853724e+00]\n",
      "Epoch [5600/6000] Loss: 4.27e-02 params: [1.5304648e-04 1.1151912e+00 4.2820663e+00]\n",
      "Epoch [5800/6000] Loss: 4.32e-02 params: [2.3147799e-05 1.1147860e+00 4.3786893e+00]\n",
      "Epoch [6000/6000] Loss: 4.26e-02 params: [6.9107773e-07 1.1142932e+00 4.4752164e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# H_8, cGEM=100\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 100])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/H_8.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e708b96-37cc-4fdc-ae50-bc5fea8a6377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=6.9107773e-07\n",
      "fm=1.1142932\n",
      "fp=4.4752164\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0dd97f4-477f-4193-888c-a99cee175dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 7.92e-02 params: [0.456466  0.728376  0.5648284]\n",
      "Epoch [400/6000] Loss: 7.09e-02 params: [0.26792398 0.94816625 0.8150009 ]\n",
      "Epoch [600/6000] Loss: 6.87e-02 params: [0.13600668 1.1036136  1.0642304 ]\n",
      "Epoch [800/6000] Loss: 6.78e-02 params: [0.05540938 1.1735176  1.2903502 ]\n",
      "Epoch [1000/6000] Loss: 6.74e-02 params: [0.00230739 1.1928709  1.502666  ]\n",
      "Epoch [1200/6000] Loss: 6.73e-02 params: [3.2276745e-05 1.1959909e+00 1.7088273e+00]\n",
      "Epoch [1400/6000] Loss: 6.72e-02 params: [4.4926284e-05 1.1965617e+00 1.9123925e+00]\n",
      "Epoch [1600/6000] Loss: 6.71e-02 params: [1.6834974e-05 1.1962538e+00 2.1142242e+00]\n",
      "Epoch [1800/6000] Loss: 6.70e-02 params: [4.5587516e-05 1.1957932e+00 2.3148763e+00]\n",
      "Epoch 01999: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [2000/6000] Loss: 6.70e-02 params: [3.5722398e-05 1.1950691e+00 2.5146537e+00]\n",
      "Epoch [2200/6000] Loss: 6.69e-02 params: [5.1427774e-05 1.1949090e+00 2.6142838e+00]\n",
      "Epoch [2400/6000] Loss: 6.69e-02 params: [5.420274e-05 1.194531e+00 2.713817e+00]\n",
      "Epoch [2600/6000] Loss: 6.68e-02 params: [5.7137218e-05 1.1942115e+00 2.8132544e+00]\n",
      "Epoch [2800/6000] Loss: 6.68e-02 params: [6.0244274e-05 1.1939055e+00 2.9126053e+00]\n",
      "Epoch [3000/6000] Loss: 6.68e-02 params: [6.3543055e-05 1.1936010e+00 3.0118892e+00]\n",
      "Epoch [3200/6000] Loss: 6.67e-02 params: [6.6985165e-05 1.1932994e+00 3.1111085e+00]\n",
      "Epoch [3400/6000] Loss: 6.67e-02 params: [7.0449474e-05 1.1930051e+00 3.2102778e+00]\n",
      "Epoch 03489: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 03595: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [3600/6000] Loss: 6.67e-02 params: [1.4881725e-06 1.1928043e+00 3.2816527e+00]\n",
      "Epoch 03677: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 03728: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 03779: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch [3800/6000] Loss: 6.67e-02 params: [2.2063941e-06 1.1927582e+00 3.2963750e+00]\n",
      "Epoch 03830: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch 03881: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 03932: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 03983: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch [4000/6000] Loss: 6.67e-02 params: [2.8037718e-08 1.1927582e+00 3.2975638e+00]\n",
      "Epoch 04034: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch 04085: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch 04136: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch 04187: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch [4200/6000] Loss: 6.67e-02 params: [7.0365358e-09 1.1927582e+00 3.2976458e+00]\n",
      "Epoch 04238: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch 04289: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch [4400/6000] Loss: 6.67e-02 params: [1.3832109e-09 1.1927582e+00 3.2976458e+00]\n",
      "Epoch [4600/6000] Loss: 6.67e-02 params: [1.1427216e-09 1.1927582e+00 3.2976458e+00]\n",
      "Epoch [4800/6000] Loss: 6.67e-02 params: [1.4061124e-09 1.1927582e+00 3.2976458e+00]\n",
      "Epoch [5000/6000] Loss: 6.67e-02 params: [1.4845976e-09 1.1927582e+00 3.2976458e+00]\n",
      "Epoch [5200/6000] Loss: 6.67e-02 params: [1.2107406e-09 1.1927582e+00 3.2976458e+00]\n",
      "Epoch [5400/6000] Loss: 6.67e-02 params: [1.5219357e-09 1.1927582e+00 3.2976458e+00]\n",
      "Epoch [5600/6000] Loss: 6.67e-02 params: [1.5532517e-09 1.1927582e+00 3.2976458e+00]\n",
      "Epoch [5800/6000] Loss: 6.67e-02 params: [1.2553286e-09 1.1927582e+00 3.2976458e+00]\n",
      "Epoch [6000/6000] Loss: 6.67e-02 params: [1.5959307e-09 1.1927582e+00 3.2976458e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# E_9, cGEM=200\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 200])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/E_9.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca138f8a-00a3-4384-93cb-ca2150ef3918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=1.5959307e-09\n",
      "fm=1.1927582\n",
      "fp=3.2976458\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e461812b-be6a-4887-b66c-9eac1f8ccc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 1.05e-01 params: [0.344596   0.22868241 0.6095434 ]\n",
      "Epoch [400/6000] Loss: 9.50e-02 params: [0.16547008 0.2552732  0.6363203 ]\n",
      "Epoch [600/6000] Loss: 9.24e-02 params: [0.00086441 0.29471874 0.6770683 ]\n",
      "Epoch [800/6000] Loss: 9.10e-02 params: [4.2807183e-05 3.4676793e-01 7.3243147e-01]\n",
      "Epoch [1000/6000] Loss: 8.97e-02 params: [2.6601123e-05 4.1180757e-01 8.0394119e-01]\n",
      "Epoch [1200/6000] Loss: 8.85e-02 params: [1.9781190e-04 4.9051711e-01 8.9453155e-01]\n",
      "Epoch [1400/6000] Loss: 8.72e-02 params: [1.6816859e-05 5.8335918e-01 1.0078924e+00]\n",
      "Epoch [1600/6000] Loss: 8.56e-02 params: [1.0746986e-05 6.8935317e-01 1.1474079e+00]\n",
      "Epoch [1800/6000] Loss: 8.39e-02 params: [1.2303647e-04 8.0415493e-01 1.3140090e+00]\n",
      "Epoch [2000/6000] Loss: 8.23e-02 params: [9.6950444e-06 9.1863126e-01 1.5033554e+00]\n",
      "Epoch [2200/6000] Loss: 8.11e-02 params: [1.6591845e-04 1.0208917e+00 1.7060133e+00]\n",
      "Epoch [2400/6000] Loss: 8.04e-02 params: [6.5680259e-05 1.1016396e+00 1.9118071e+00]\n",
      "Epoch [2600/6000] Loss: 8.01e-02 params: [4.4672459e-05 1.1583731e+00 2.1148047e+00]\n",
      "Epoch [2800/6000] Loss: 7.99e-02 params: [3.0817682e-07 1.1942399e+00 2.3135555e+00]\n",
      "Epoch 02923: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [3000/6000] Loss: 7.98e-02 params: [5.6133871e-05 1.2117405e+00 2.4721489e+00]\n",
      "Epoch [3200/6000] Loss: 7.97e-02 params: [1.9570454e-05 1.2190154e+00 2.5696087e+00]\n",
      "Epoch [3400/6000] Loss: 7.97e-02 params: [2.1877988e-05 1.2242395e+00 2.6669614e+00]\n",
      "Epoch [3600/6000] Loss: 7.96e-02 params: [2.0675514e-05 1.2277935e+00 2.7643483e+00]\n",
      "Epoch [3800/6000] Loss: 7.96e-02 params: [1.1798682e-05 1.2300390e+00 2.8618541e+00]\n",
      "Epoch [4000/6000] Loss: 7.96e-02 params: [2.4190507e-05 1.2313110e+00 2.9595373e+00]\n",
      "Epoch [4200/6000] Loss: 7.95e-02 params: [2.0443582e-05 1.2319047e+00 3.0574214e+00]\n",
      "Epoch 04332: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 04389: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [4400/6000] Loss: 7.95e-02 params: [1.6933898e-06 1.2320576e+00 3.1378369e+00]\n",
      "Epoch 04482: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 04533: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 04584: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch [4600/6000] Loss: 7.95e-02 params: [2.8388337e-07 1.2320665e+00 3.1529684e+00]\n",
      "Epoch 04635: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch 04686: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 04737: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 04788: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch [4800/6000] Loss: 7.95e-02 params: [1.8926723e-08 1.2320665e+00 3.1542177e+00]\n",
      "Epoch 04839: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch 04890: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch 04941: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch 04992: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch [5000/6000] Loss: 7.95e-02 params: [5.5314695e-09 1.2320665e+00 3.1543045e+00]\n",
      "Epoch 05043: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch 05094: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch [5200/6000] Loss: 7.95e-02 params: [5.5303828e-10 1.2320665e+00 3.1543045e+00]\n",
      "Epoch [5400/6000] Loss: 7.95e-02 params: [2.3707156e-09 1.2320665e+00 3.1543045e+00]\n",
      "Epoch [5600/6000] Loss: 7.95e-02 params: [2.2284401e-09 1.2320665e+00 3.1543045e+00]\n",
      "Epoch [5800/6000] Loss: 7.95e-02 params: [1.1644387e-09 1.2320665e+00 3.1543045e+00]\n",
      "Epoch [6000/6000] Loss: 7.95e-02 params: [6.8328160e-10 1.2320665e+00 3.1543045e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# F_9, cGEM=200\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 200])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/F_9.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12e855f9-6789-43ef-9b83-fa26f41ddd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=6.832816e-10\n",
      "fm=1.2320665\n",
      "fp=3.1543045\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b030347-bd85-425e-8ac6-0e7f90ff660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 6.50e-02 params: [0.24874143 0.2140818  0.2816104 ]\n",
      "Epoch [400/6000] Loss: 5.75e-02 params: [0.03473947 0.47155347 0.54635394]\n",
      "Epoch [600/6000] Loss: 5.35e-02 params: [1.2779509e-04 7.2484499e-01 8.3889824e-01]\n",
      "Epoch [800/6000] Loss: 5.09e-02 params: [3.5089131e-05 9.4259596e-01 1.1312717e+00]\n",
      "Epoch [1000/6000] Loss: 4.98e-02 params: [1.9683297e-05 1.0929873e+00 1.4003252e+00]\n",
      "Epoch [1200/6000] Loss: 4.95e-02 params: [9.5363957e-06 1.1750771e+00 1.6420807e+00]\n",
      "Epoch 01366: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1400/6000] Loss: 4.94e-02 params: [1.8286368e-05 1.2089437e+00 1.8475019e+00]\n",
      "Epoch [1600/6000] Loss: 4.93e-02 params: [6.9660741e-06 1.2179531e+00 1.9547528e+00]\n",
      "Epoch [1800/6000] Loss: 4.93e-02 params: [1.6777790e-08 1.2230169e+00 2.0596027e+00]\n",
      "Epoch [2000/6000] Loss: 4.93e-02 params: [2.7962242e-06 1.2255871e+00 2.1629024e+00]\n",
      "Epoch [2200/6000] Loss: 4.93e-02 params: [1.6177190e-05 1.2266839e+00 2.2651680e+00]\n",
      "Epoch [2400/6000] Loss: 4.92e-02 params: [6.9104624e-07 1.2269828e+00 2.3667145e+00]\n",
      "Epoch [2600/6000] Loss: 4.96e-02 params: [3.6803594e-05 1.2268970e+00 2.4677470e+00]\n",
      "Epoch 02616: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 02671: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 02762: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch [2800/6000] Loss: 4.92e-02 params: [1.2054443e-08 1.2268322e+00 2.5039351e+00]\n",
      "Epoch 02813: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 02864: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 02915: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch 02966: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch [3000/6000] Loss: 4.92e-02 params: [7.9230837e-08 1.2268244e+00 2.5077510e+00]\n",
      "Epoch 03017: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 03068: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 03119: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch 03170: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch [3200/6000] Loss: 4.92e-02 params: [3.6628387e-09 1.2268244e+00 2.5079968e+00]\n",
      "Epoch 03221: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch 03272: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch 03323: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch 03374: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch [3400/6000] Loss: 4.92e-02 params: [6.6193551e-11 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [3600/6000] Loss: 4.92e-02 params: [7.1154915e-11 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [3800/6000] Loss: 4.92e-02 params: [3.0780856e-10 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [4000/6000] Loss: 4.92e-02 params: [6.8389927e-10 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [4200/6000] Loss: 4.92e-02 params: [5.8641203e-11 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [4400/6000] Loss: 4.92e-02 params: [4.6243528e-10 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [4600/6000] Loss: 4.92e-02 params: [5.4383381e-10 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [4800/6000] Loss: 4.92e-02 params: [1.6597085e-10 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [5000/6000] Loss: 4.92e-02 params: [1.1977502e-10 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [5200/6000] Loss: 4.92e-02 params: [5.5968219e-10 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [5400/6000] Loss: 4.92e-02 params: [1.1839228e-09 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [5600/6000] Loss: 4.92e-02 params: [9.1089358e-11 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [5800/6000] Loss: 4.92e-02 params: [7.5652484e-10 1.2268244e+00 2.5080142e+00]\n",
      "Epoch [6000/6000] Loss: 4.92e-02 params: [8.8011959e-10 1.2268244e+00 2.5080142e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# G_9, cGEM=200\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 200])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/G_9.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a01902f7-75b7-4313-bf21-c0b7d55527b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=8.801196e-10\n",
      "fm=1.2268244\n",
      "fp=2.5080142\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5db7e82-c467-47cb-a0fd-6a01a12150b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 6.75e-02 params: [0.63290405 0.66577494 0.7333045 ]\n",
      "Epoch [400/6000] Loss: 6.22e-02 params: [0.4362826 0.8587542 0.9527434]\n",
      "Epoch [600/6000] Loss: 5.86e-02 params: [0.28569385 1.0266832  1.1939393 ]\n",
      "Epoch [800/6000] Loss: 5.69e-02 params: [0.1872314 1.1312431 1.4261549]\n",
      "Epoch [1000/6000] Loss: 5.64e-02 params: [0.12884507 1.1772256  1.643751  ]\n",
      "Epoch [1200/6000] Loss: 5.61e-02 params: [0.09007017 1.190358   1.8526031 ]\n",
      "Epoch [1400/6000] Loss: 5.59e-02 params: [0.0575544 1.1902305 2.0580626]\n",
      "Epoch [1600/6000] Loss: 5.57e-02 params: [0.02552339 1.1857156  2.2623765 ]\n",
      "Epoch [1800/6000] Loss: 5.55e-02 params: [2.0690961e-05 1.1804650e+00 2.4661593e+00]\n",
      "Epoch 01848: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [2000/6000] Loss: 5.54e-02 params: [2.1467742e-05 1.1793941e+00 2.5928941e+00]\n",
      "Epoch [2200/6000] Loss: 5.54e-02 params: [2.3610690e-05 1.1790680e+00 2.6943555e+00]\n",
      "Epoch [2400/6000] Loss: 5.53e-02 params: [2.5560954e-05 1.1792120e+00 2.7955923e+00]\n",
      "Epoch [2600/6000] Loss: 5.52e-02 params: [2.7501857e-05 1.1795573e+00 2.8966358e+00]\n",
      "Epoch [2800/6000] Loss: 5.52e-02 params: [2.9531724e-05 1.1799541e+00 2.9974964e+00]\n",
      "Epoch [3000/6000] Loss: 5.51e-02 params: [3.1741001e-05 1.1803652e+00 3.0981770e+00]\n",
      "Epoch [3200/6000] Loss: 5.50e-02 params: [2.1810523e-05 1.1807760e+00 3.1986759e+00]\n",
      "Epoch [3400/6000] Loss: 5.50e-02 params: [2.2544542e-05 1.1811666e+00 3.2989526e+00]\n",
      "Epoch [3600/6000] Loss: 5.49e-02 params: [2.2877588e-05 1.1815913e+00 3.3990276e+00]\n",
      "Epoch [3800/6000] Loss: 5.48e-02 params: [8.9268135e-05 1.1820040e+00 3.4989164e+00]\n",
      "Epoch [4000/6000] Loss: 5.58e-02 params: [1.8121855e-05 1.1823421e+00 3.5985832e+00]\n",
      "Epoch 04026: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [4200/6000] Loss: 5.48e-02 params: [2.5917116e-06 1.1825186e+00 3.6551223e+00]\n",
      "Epoch [4400/6000] Loss: 5.47e-02 params: [4.4413264e-06 1.1826925e+00 3.7049041e+00]\n",
      "Epoch [4600/6000] Loss: 5.47e-02 params: [5.5461169e-06 1.1829474e+00 3.7546859e+00]\n",
      "Epoch [4800/6000] Loss: 5.47e-02 params: [6.4636861e-06 1.1832066e+00 3.8044496e+00]\n",
      "Epoch [5000/6000] Loss: 5.47e-02 params: [7.4296477e-06 1.1834477e+00 3.8541837e+00]\n",
      "Epoch [5200/6000] Loss: 5.46e-02 params: [8.2005681e-06 1.1836585e+00 3.9039178e+00]\n",
      "Epoch 05359: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [5400/6000] Loss: 5.46e-02 params: [1.4859604e-05 1.1838262e+00 3.9486864e+00]\n",
      "Epoch 05425: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 05476: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 05527: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 05578: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch [5600/6000] Loss: 5.46e-02 params: [2.8981216e-07 1.1838260e+00 3.9576290e+00]\n",
      "Epoch 05629: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 05680: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 05731: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 05782: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch [5800/6000] Loss: 5.46e-02 params: [9.7149496e-08 1.1838260e+00 3.9582136e+00]\n",
      "Epoch 05833: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch 05884: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch 05935: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch 05986: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch [6000/6000] Loss: 5.46e-02 params: [3.927663e-09 1.183826e+00 3.958254e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# H_9, cGEM=200\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 200])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/H_9.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d97b8d7-b084-4ef2-b531-a8d13f6c8c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=3.927663e-09\n",
      "fm=1.183826\n",
      "fp=3.958254\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d837b7d3-b51d-4518-828c-6ec23999a9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 9.31e-02 params: [0.17479105 0.37948513 0.3964633 ]\n",
      "Epoch [400/6000] Loss: 6.99e-02 params: [0.07122979 0.38805473 0.41266134]\n",
      "Epoch [600/6000] Loss: 6.80e-02 params: [4.1940330e-05 4.0080038e-01 4.3652922e-01]\n",
      "Epoch [800/6000] Loss: 6.71e-02 params: [7.1505725e-05 4.2027915e-01 4.6952626e-01]\n",
      "Epoch [1000/6000] Loss: 6.64e-02 params: [1.0625911e-04 4.4538140e-01 5.1096416e-01]\n",
      "Epoch [1200/6000] Loss: 6.60e-02 params: [1.1613925e-04 4.7508124e-01 5.6038129e-01]\n",
      "Epoch [1400/6000] Loss: 6.58e-02 params: [1.3714764e-04 5.0886500e-01 6.1799812e-01]\n",
      "Epoch 01482: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1600/6000] Loss: 6.57e-02 params: [1.2356668e-07 5.3527534e-01 6.6426611e-01]\n",
      "Epoch [1800/6000] Loss: 6.56e-02 params: [2.5844914e-05 5.5625743e-01 7.0157707e-01]\n",
      "Epoch [2000/6000] Loss: 6.55e-02 params: [4.3139615e-05 5.7940686e-01 7.4327463e-01]\n",
      "Epoch [2200/6000] Loss: 6.55e-02 params: [8.1517748e-05 6.0473174e-01 7.8949827e-01]\n",
      "Epoch [2400/6000] Loss: 6.54e-02 params: [3.3123797e-07 6.3221860e-01 8.4035879e-01]\n",
      "Epoch [2600/6000] Loss: 6.53e-02 params: [4.4481400e-05 6.6180784e-01 8.9592272e-01]\n",
      "Epoch [2800/6000] Loss: 6.53e-02 params: [3.3833498e-05 6.9336975e-01 9.5618773e-01]\n",
      "Epoch [3000/6000] Loss: 6.52e-02 params: [5.3955719e-05 7.2672886e-01 1.0211093e+00]\n",
      "Epoch [3200/6000] Loss: 6.51e-02 params: [3.1315030e-05 7.6159549e-01 1.0905331e+00]\n",
      "Epoch [3400/6000] Loss: 6.51e-02 params: [2.9603161e-05 7.9764253e-01 1.1642600e+00]\n",
      "Epoch [3600/6000] Loss: 6.50e-02 params: [4.5405555e-05 8.3449614e-01 1.2419939e+00]\n",
      "Epoch [3800/6000] Loss: 6.49e-02 params: [2.9550132e-05 8.7162697e-01 1.3232939e+00]\n",
      "Epoch [4000/6000] Loss: 6.48e-02 params: [2.0665289e-05 9.0854776e-01 1.4077629e+00]\n",
      "Epoch [4200/6000] Loss: 6.48e-02 params: [3.7843012e-05 9.4469696e-01 1.4949505e+00]\n",
      "Epoch 04375: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [4400/6000] Loss: 6.47e-02 params: [6.8093050e-06 9.7749835e-01 1.5790126e+00]\n",
      "Epoch [4600/6000] Loss: 6.47e-02 params: [7.2966395e-06 9.9469984e-01 1.6246390e+00]\n",
      "Epoch [4800/6000] Loss: 6.46e-02 params: [4.8928887e-06 1.0120614e+00 1.6710291e+00]\n",
      "Epoch [5000/6000] Loss: 6.46e-02 params: [1.0741794e-05 1.0294057e+00 1.7180367e+00]\n",
      "Epoch [5200/6000] Loss: 6.46e-02 params: [4.9524551e-06 1.0465707e+00 1.7655473e+00]\n",
      "Epoch [5400/6000] Loss: 6.45e-02 params: [2.6610760e-06 1.0633836e+00 1.8134637e+00]\n",
      "Epoch [5600/6000] Loss: 6.45e-02 params: [3.6445895e-06 1.0796691e+00 1.8617024e+00]\n",
      "Epoch [5800/6000] Loss: 6.45e-02 params: [1.6607838e-06 1.0952531e+00 1.9101920e+00]\n",
      "Epoch 05922: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 05987: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch [6000/6000] Loss: 6.44e-02 params: [1.2076304e-03 1.1070297e+00 1.9487678e+00]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# E_1_0, cGEM=400\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 400])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/E_1_0.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9755940e-4905-4a27-b6e5-7cce5157fe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.0012076304\n",
      "fm=1.1070297\n",
      "fp=1.9487678\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79d428e2-0920-44e0-9790-6dd60d06d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 9.23e-02 params: [0.6259658 0.8211865 1.1000136]\n",
      "Epoch [400/6000] Loss: 9.03e-02 params: [0.44858184 1.0345337  1.3316716 ]\n",
      "Epoch [600/6000] Loss: 8.57e-02 params: [0.32183766 1.2018756  1.5625621 ]\n",
      "Epoch [800/6000] Loss: 8.45e-02 params: [0.24533188 1.3174976  1.7781011 ]\n",
      "Epoch [1000/6000] Loss: 8.39e-02 params: [0.21281305 1.3955349  1.9830164 ]\n",
      "Epoch [1200/6000] Loss: 8.38e-02 params: [0.2139319 1.4478629 2.1830149]\n",
      "Epoch 01248: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1400/6000] Loss: 8.37e-02 params: [0.22731966 1.4724258  2.3063123 ]\n",
      "Epoch [1600/6000] Loss: 8.36e-02 params: [0.2440103 1.4897121 2.4050653]\n",
      "Epoch [1800/6000] Loss: 8.36e-02 params: [0.2651378 1.5059513 2.5038657]\n",
      "Epoch [2000/6000] Loss: 8.35e-02 params: [0.28990108 1.5216918  2.6027393 ]\n",
      "Epoch [2200/6000] Loss: 8.43e-02 params: [0.3174419 1.5372692 2.7017047]\n",
      "Epoch 02229: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 02304: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 02386: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch [2400/6000] Loss: 8.34e-02 params: [0.33064064 1.5443834  2.7461112 ]\n",
      "Epoch 02437: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 02488: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 02539: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch 02590: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch [2600/6000] Loss: 8.34e-02 params: [0.33230376 1.5452704  2.7512734 ]\n",
      "Epoch 02641: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 02692: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 02743: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch 02794: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch [2800/6000] Loss: 8.34e-02 params: [0.33242312 1.545337   2.751605  ]\n",
      "Epoch 02845: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch 02896: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch 02947: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch 02998: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch [3000/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [3200/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [3400/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [3600/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [3800/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [4000/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [4200/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [4400/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [4600/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [4800/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [5000/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [5200/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [5400/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [5600/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [5800/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Epoch [6000/6000] Loss: 8.34e-02 params: [0.3324318 1.545337  2.7516282]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# F_1_0, cGEM=400\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 400])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/F_1_0.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f346ca9-ee87-460c-84d5-209d50584b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.3324318\n",
      "fm=1.545337\n",
      "fp=2.7516282\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e1d78ff7-3019-42cc-a1d3-bcac9212e273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 8.31e-02 params: [0.03957856 0.98754776 1.0067217 ]\n",
      "Epoch [400/6000] Loss: 6.22e-02 params: [4.2567823e-05 1.0058291e+00 1.0713180e+00]\n",
      "Epoch [600/6000] Loss: 5.98e-02 params: [1.0317544e-05 1.0444534e+00 1.1680903e+00]\n",
      "Epoch [800/6000] Loss: 5.84e-02 params: [5.6548710e-05 1.0844729e+00 1.2843903e+00]\n",
      "Epoch [1000/6000] Loss: 5.79e-02 params: [1.4897223e-04 1.1208252e+00 1.4149680e+00]\n",
      "Epoch [1200/6000] Loss: 5.75e-02 params: [0.01254778 1.1524143  1.5575848 ]\n",
      "Epoch 01373: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1400/6000] Loss: 5.73e-02 params: [0.05028008 1.1823404  1.7005999 ]\n",
      "Epoch [1600/6000] Loss: 5.72e-02 params: [0.07652012 1.2005979  1.781318  ]\n",
      "Epoch [1800/6000] Loss: 5.71e-02 params: [0.10637888 1.2216295  1.8656718 ]\n",
      "Epoch [2000/6000] Loss: 5.71e-02 params: [0.14050391 1.2456528  1.9529779 ]\n",
      "Epoch [2200/6000] Loss: 5.70e-02 params: [0.17922157 1.273153   2.0427566 ]\n",
      "Epoch [2400/6000] Loss: 5.69e-02 params: [0.2228502 1.304501  2.134596 ]\n",
      "Epoch [2600/6000] Loss: 5.69e-02 params: [0.27144292 1.3398536  2.2281332 ]\n",
      "Epoch [2800/6000] Loss: 5.75e-02 params: [0.3247362 1.3790674 2.3230724]\n",
      "Epoch 02808: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [3000/6000] Loss: 5.68e-02 params: [0.3546153 1.4012101 2.3731656]\n",
      "Epoch [3200/6000] Loss: 5.68e-02 params: [0.38529244 1.4241059  2.4215434 ]\n",
      "Epoch [3400/6000] Loss: 5.68e-02 params: [0.4178391 1.4485091 2.4702418]\n",
      "Epoch [3600/6000] Loss: 5.67e-02 params: [0.4520273 1.4742973 2.5191934]\n",
      "Epoch [3800/6000] Loss: 5.67e-02 params: [0.48757386 1.5012845  2.568338  ]\n",
      "Epoch [4000/6000] Loss: 5.67e-02 params: [0.5241433 1.5292252 2.617624 ]\n",
      "Epoch [4200/6000] Loss: 5.66e-02 params: [0.5613537 1.5578306 2.6670043]\n",
      "Epoch 04207: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 04311: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch [4400/6000] Loss: 5.66e-02 params: [0.5768157 1.5698147 2.6872663]\n",
      "Epoch 04409: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 04460: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 04511: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch 04562: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch [4600/6000] Loss: 5.66e-02 params: [0.5795775 1.5719872 2.6907852]\n",
      "Epoch 04613: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 04664: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 04715: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch 04766: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch [4800/6000] Loss: 5.66e-02 params: [0.57976663 1.5721397  2.6910167 ]\n",
      "Epoch 04817: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch 04868: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch 04919: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch 04970: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch [5000/6000] Loss: 5.66e-02 params: [0.57977897 1.572148   2.6910331 ]\n",
      "Epoch [5200/6000] Loss: 5.66e-02 params: [0.57977897 1.572148   2.6910331 ]\n",
      "Epoch [5400/6000] Loss: 5.66e-02 params: [0.57977897 1.572148   2.6910331 ]\n",
      "Epoch [5600/6000] Loss: 5.66e-02 params: [0.57977897 1.572148   2.6910331 ]\n",
      "Epoch [5800/6000] Loss: 5.66e-02 params: [0.57977897 1.572148   2.6910331 ]\n",
      "Epoch [6000/6000] Loss: 5.66e-02 params: [0.57977897 1.572148   2.6910331 ]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# G_1_0, cGEM=400\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 400])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/G_1_0.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2cd0df00-ffb4-4c1b-aad4-14563764604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.57977897\n",
      "fm=1.572148\n",
      "fp=2.6910331\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be963e34-2c87-4141-a2d5-04e572151098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 8.53e-02 params: [0.16768226 0.86421543 0.5604614 ]\n",
      "Epoch [400/6000] Loss: 8.11e-02 params: [0.02327862 1.0674002  0.8018701 ]\n",
      "Epoch [600/6000] Loss: 7.81e-02 params: [2.7326887e-04 1.1934761e+00 1.0277101e+00]\n",
      "Epoch [800/6000] Loss: 7.55e-02 params: [0.05352505 1.2761959  1.242621  ]\n",
      "Epoch [1000/6000] Loss: 7.37e-02 params: [0.17446132 1.3623489  1.4517132 ]\n",
      "Epoch [1200/6000] Loss: 7.34e-02 params: [0.32026502 1.4599266  1.659073  ]\n",
      "Epoch [1400/6000] Loss: 7.31e-02 params: [0.46641466 1.5516701  1.8648331 ]\n",
      "Epoch [1600/6000] Loss: 7.29e-02 params: [0.5980778 1.6299384 2.0686812]\n",
      "Epoch 01669: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1800/6000] Loss: 7.28e-02 params: [0.6747599 1.6740144 2.2054224]\n",
      "Epoch [2000/6000] Loss: 7.27e-02 params: [0.7268355 1.7032079 2.3054628]\n",
      "Epoch [2200/6000] Loss: 7.26e-02 params: [0.7739929 1.7295457 2.4053094]\n",
      "Epoch [2400/6000] Loss: 7.24e-02 params: [0.8153701 1.7527975 2.5050118]\n",
      "Epoch [2600/6000] Loss: 7.23e-02 params: [0.8503819 1.7725139 2.604663 ]\n",
      "Epoch [2800/6000] Loss: 7.22e-02 params: [0.8787339 1.788775  2.7042007]\n",
      "Epoch [3000/6000] Loss: 7.21e-02 params: [0.90062016 1.8014108  2.8036153 ]\n",
      "Epoch 03188: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [3200/6000] Loss: 7.20e-02 params: [0.9161852 1.810297  2.900198 ]\n",
      "Epoch [3400/6000] Loss: 7.19e-02 params: [0.92222863 1.8144257  2.949786  ]\n",
      "Epoch [3600/6000] Loss: 7.19e-02 params: [0.9273149 1.8176597 2.999408 ]\n",
      "Epoch [3800/6000] Loss: 7.18e-02 params: [0.9312159 1.82048   3.0490623]\n",
      "Epoch [4000/6000] Loss: 7.18e-02 params: [0.93398494 1.822876   3.0987487 ]\n",
      "Epoch [4200/6000] Loss: 7.17e-02 params: [0.9357089 1.8248686 3.148435 ]\n",
      "Epoch [4400/6000] Loss: 7.17e-02 params: [0.9365297 1.8265026 3.198131 ]\n",
      "Epoch [4600/6000] Loss: 7.17e-02 params: [0.9367327 1.827928  3.247823 ]\n",
      "Epoch [4800/6000] Loss: 7.16e-02 params: [0.9366345 1.8290893 3.297524 ]\n",
      "Epoch 04932: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 04985: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch [5000/6000] Loss: 7.16e-02 params: [0.93646145 1.8300089  3.3380365 ]\n",
      "Epoch 05036: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 05137: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 05188: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch [5200/6000] Loss: 7.16e-02 params: [0.9364492 1.8301765 3.3443463]\n",
      "Epoch 05239: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 05290: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 05341: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 05392: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch [5400/6000] Loss: 7.16e-02 params: [0.9364492 1.8301921 3.3450048]\n",
      "Epoch 05443: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch 05494: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch 05545: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch 05596: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch [5600/6000] Loss: 7.16e-02 params: [0.9364492 1.8301921 3.34505  ]\n",
      "Epoch 05647: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch [5800/6000] Loss: 7.16e-02 params: [0.9364492 1.8301921 3.34505  ]\n",
      "Epoch [6000/6000] Loss: 7.16e-02 params: [0.9364492 1.8301921 3.34505  ]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# H_1_0, cGEM=400\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 400])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/H_1_0.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6cc7e485-4dd2-4776-8983-d10d59d8f2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.9364492\n",
      "fm=1.8301921\n",
      "fp=3.34505\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2763b3aa-6903-460c-955d-04eac3f39fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 1.24e-01 params: [0.9286952  0.63773704 0.97067446]\n",
      "Epoch [400/6000] Loss: 7.23e-02 params: [0.8352566 0.6380765 0.9714807]\n",
      "Epoch [600/6000] Loss: 6.67e-02 params: [0.71847856 0.6388872  0.97284335]\n",
      "Epoch [800/6000] Loss: 6.53e-02 params: [0.6039174 0.6399062 0.9746602]\n",
      "Epoch [1000/6000] Loss: 6.44e-02 params: [0.50334483 0.64094335 0.97687274]\n",
      "Epoch [1200/6000] Loss: 6.37e-02 params: [0.42065483 0.6419512  0.97947043]\n",
      "Epoch [1400/6000] Loss: 6.32e-02 params: [0.35719404 0.6428941  0.98246527]\n",
      "Epoch [1600/6000] Loss: 6.29e-02 params: [0.31204763 0.6437693  0.98588496]\n",
      "Epoch [1800/6000] Loss: 6.27e-02 params: [0.28198704 0.64456654 0.9897645 ]\n",
      "Epoch [2000/6000] Loss: 6.26e-02 params: [0.26292562 0.6452806  0.9941548 ]\n",
      "Epoch [2200/6000] Loss: 6.25e-02 params: [0.2515051  0.64594275 0.99911284]\n",
      "Epoch [2400/6000] Loss: 6.25e-02 params: [0.24543737 0.6466004  1.0046887 ]\n",
      "Epoch [2600/6000] Loss: 6.24e-02 params: [0.24295107 0.64730036 1.0109292 ]\n",
      "Epoch [2800/6000] Loss: 6.24e-02 params: [0.24228224 0.6480866  1.0178928 ]\n",
      "Epoch [3000/6000] Loss: 6.23e-02 params: [0.24215686 0.64899224 1.025639  ]\n",
      "Epoch 03053: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [3200/6000] Loss: 6.22e-02 params: [0.2420761  0.64965767 1.0310701 ]\n",
      "Epoch [3400/6000] Loss: 6.22e-02 params: [0.24186845 0.6502593  1.0358528 ]\n",
      "Epoch [3600/6000] Loss: 6.22e-02 params: [0.24152969 0.65094715 1.0411605 ]\n",
      "Epoch [3800/6000] Loss: 6.21e-02 params: [0.241071  0.6517358 1.0470461]\n",
      "Epoch [4000/6000] Loss: 6.21e-02 params: [0.24049492 0.6526408  1.0535676 ]\n",
      "Epoch [4200/6000] Loss: 6.21e-02 params: [0.23979564 0.6536797  1.0607896 ]\n",
      "Epoch [4400/6000] Loss: 6.20e-02 params: [0.23895979 0.65487194 1.0687822 ]\n",
      "Epoch 04493: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [4600/6000] Loss: 6.20e-02 params: [0.23827218 0.65586466 1.0752258 ]\n",
      "Epoch [4800/6000] Loss: 6.20e-02 params: [0.237737  0.6566333 1.0801108]\n",
      "Epoch [5000/6000] Loss: 6.19e-02 params: [0.23713282 0.6574968  1.0855082 ]\n",
      "Epoch [5200/6000] Loss: 6.19e-02 params: [0.23644981 0.65846664 1.0914694 ]\n",
      "Epoch [5400/6000] Loss: 6.19e-02 params: [0.23567414 0.659555   1.0980502 ]\n",
      "Epoch [5600/6000] Loss: 6.18e-02 params: [0.23478909 0.6607756  1.1053113 ]\n",
      "Epoch [5800/6000] Loss: 6.18e-02 params: [0.23377723 0.6621431  1.1133186 ]\n",
      "Epoch [6000/6000] Loss: 6.17e-02 params: [0.23262458 0.66367507 1.1221453 ]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# E_1_1, cGEM=800\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 800])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/E_1_1.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91d4dc57-6dd2-4745-8962-e6a712669d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.23262458\n",
      "fm=0.66367507\n",
      "fp=1.1221453\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "989d3246-3072-4d8c-b828-efa13b7eafb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 9.11e-02 params: [0.17063612 0.7386125  0.34696758]\n",
      "Epoch [400/6000] Loss: 8.15e-02 params: [0.14184369 0.7268779  0.37928057]\n",
      "Epoch [600/6000] Loss: 8.01e-02 params: [0.10472299 0.7159409  0.42738083]\n",
      "Epoch [800/6000] Loss: 7.88e-02 params: [0.07531524 0.7035174  0.48551378]\n",
      "Epoch [1000/6000] Loss: 7.78e-02 params: [0.06236503 0.6899714  0.552377  ]\n",
      "Epoch [1200/6000] Loss: 7.72e-02 params: [0.06626911 0.6799857  0.63207185]\n",
      "Epoch [1400/6000] Loss: 7.68e-02 params: [0.07084955 0.67031574 0.7205501 ]\n",
      "Epoch 01500: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1600/6000] Loss: 7.67e-02 params: [0.07271408 0.66405344 0.7941748 ]\n",
      "Epoch [1800/6000] Loss: 7.66e-02 params: [0.07311676 0.657624   0.8465374 ]\n",
      "Epoch [2000/6000] Loss: 7.66e-02 params: [0.07241961 0.65090734 0.9036463 ]\n",
      "Epoch [2200/6000] Loss: 7.65e-02 params: [0.07063818 0.64393276 0.9653252 ]\n",
      "Epoch [2400/6000] Loss: 7.65e-02 params: [0.06783809 0.63666826 1.0313339 ]\n",
      "Epoch 02486: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [2600/6000] Loss: 7.64e-02 params: [0.06525557 0.63127655 1.0813875 ]\n",
      "Epoch 02631: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 02683: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 02734: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 02785: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch [2800/6000] Loss: 7.64e-02 params: [0.06444159 0.629691   1.0956278 ]\n",
      "Epoch 02836: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch 02932: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 02983: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch [3000/6000] Loss: 7.64e-02 params: [0.06436773 0.6295505  1.096826  ]\n",
      "Epoch 03034: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 03085: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch 03136: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch 03187: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch [3200/6000] Loss: 7.64e-02 params: [0.06435933 0.62953514 1.0969546 ]\n",
      "Epoch 03238: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch 03289: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch 03340: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch [3400/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [3600/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [3800/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [4000/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [4200/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [4400/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [4600/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [4800/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [5000/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [5200/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [5400/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [5600/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [5800/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Epoch [6000/6000] Loss: 7.64e-02 params: [0.06435904 0.62953514 1.0969592 ]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# F_1_1, cGEM=800\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 800])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/F_1_1.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8579ca06-6509-4e8b-aaf9-dd5b7ead6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.06435904\n",
      "fm=0.62953514\n",
      "fp=1.0969592\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f742fa18-18b4-404b-9a86-761c7e428ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 5.96e-02 params: [0.92413116 0.45532396 0.5568676 ]\n",
      "Epoch [400/6000] Loss: 5.12e-02 params: [0.863568   0.45720732 0.5587426 ]\n",
      "Epoch [600/6000] Loss: 4.99e-02 params: [0.7888592  0.45979068 0.5618728 ]\n",
      "Epoch [800/6000] Loss: 4.84e-02 params: [0.70791817 0.4628213  0.56598634]\n",
      "Epoch [1000/6000] Loss: 4.71e-02 params: [0.6266822 0.4660703 0.5706814]\n",
      "Epoch [1200/6000] Loss: 4.68e-02 params: [0.54785496 0.4697924  0.57610255]\n",
      "Epoch [1400/6000] Loss: 4.67e-02 params: [0.47181153 0.47381616 0.58238   ]\n",
      "Epoch [1600/6000] Loss: 4.68e-02 params: [0.3999746  0.47796896 0.589575  ]\n",
      "Epoch [1800/6000] Loss: 4.65e-02 params: [0.333754   0.48214602 0.5977476 ]\n",
      "Epoch [2000/6000] Loss: 4.65e-02 params: [0.2742442  0.48625705 0.6069667 ]\n",
      "Epoch 02042: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 02104: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 02167: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [2200/6000] Loss: 4.65e-02 params: [0.2487457  0.48815474 0.6117199 ]\n",
      "Epoch 02218: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 02269: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 02320: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 02371: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch [2400/6000] Loss: 4.65e-02 params: [0.2464576  0.48833153 0.61218196]\n",
      "Epoch 02422: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 02473: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 02524: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 02575: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch [2600/6000] Loss: 4.65e-02 params: [0.24629144 0.48834476 0.61221564]\n",
      "Epoch 02626: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch 02677: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch 02728: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch 02779: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch [2800/6000] Loss: 4.65e-02 params: [0.2462793  0.48834476 0.61221725]\n",
      "Epoch 02830: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch [3000/6000] Loss: 4.65e-02 params: [0.24627884 0.48834476 0.61221725]\n",
      "Epoch [3200/6000] Loss: 4.65e-02 params: [0.24627884 0.48834476 0.61221725]\n",
      "Epoch [3400/6000] Loss: 4.65e-02 params: [0.24627884 0.48834476 0.61221725]\n",
      "Epoch [3600/6000] Loss: 4.65e-02 params: [0.24627732 0.48834476 0.61221725]\n",
      "Epoch [3800/6000] Loss: 4.65e-02 params: [0.24627434 0.48834476 0.61221725]\n",
      "Epoch [4000/6000] Loss: 4.65e-02 params: [0.24627136 0.48834476 0.61221725]\n",
      "Epoch [4200/6000] Loss: 4.65e-02 params: [0.24626838 0.48834476 0.61221725]\n",
      "Epoch [4400/6000] Loss: 4.65e-02 params: [0.2462654  0.48834476 0.61221725]\n",
      "Epoch [4600/6000] Loss: 4.65e-02 params: [0.24626242 0.48834476 0.61221725]\n",
      "Epoch [4800/6000] Loss: 4.65e-02 params: [0.24625944 0.48834476 0.61221725]\n",
      "Epoch [5000/6000] Loss: 4.65e-02 params: [0.24625646 0.48834476 0.61221725]\n",
      "Epoch [5200/6000] Loss: 4.65e-02 params: [0.24625348 0.48834476 0.61221725]\n",
      "Epoch [5400/6000] Loss: 4.65e-02 params: [0.2462505  0.48834476 0.61221725]\n",
      "Epoch [5600/6000] Loss: 4.65e-02 params: [0.24624752 0.48834476 0.61221725]\n",
      "Epoch [5800/6000] Loss: 4.65e-02 params: [0.24624453 0.48834476 0.61221725]\n",
      "Epoch [6000/6000] Loss: 4.65e-02 params: [0.24624155 0.48834476 0.61221725]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# G_1_1, cGEM=800\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 800])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/G_1_1.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99cfe4ee-f60f-48e9-b8b2-4bbc938187d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.24624155\n",
      "fm=0.48834476\n",
      "fp=0.61221725\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "984480d0-5739-46dc-b4a7-41e3f2ac2fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/6000] Loss: 7.47e-02 params: [0.41937447 0.97533095 0.31205902]\n",
      "Epoch [400/6000] Loss: 6.61e-02 params: [0.36295927 0.98036677 0.3168409 ]\n",
      "Epoch [600/6000] Loss: 6.42e-02 params: [0.30480108 0.9862511  0.3236208 ]\n",
      "Epoch [800/6000] Loss: 6.09e-02 params: [0.26117033 0.9934751  0.3320907 ]\n",
      "Epoch [1000/6000] Loss: 5.73e-02 params: [0.25049317 1.0026685  0.34237757]\n",
      "Epoch [1200/6000] Loss: 5.64e-02 params: [0.27143803 1.0131603  0.35475716]\n",
      "Epoch [1400/6000] Loss: 5.61e-02 params: [0.2978678  1.0255259  0.36920884]\n",
      "Epoch [1600/6000] Loss: 5.63e-02 params: [0.31885204 1.0402637  0.38584784]\n",
      "Epoch 01602: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [1800/6000] Loss: 5.59e-02 params: [0.32739615 1.048919   0.39545423]\n",
      "Epoch [2000/6000] Loss: 5.58e-02 params: [0.33539507 1.0586244  0.40617102]\n",
      "Epoch [2200/6000] Loss: 5.58e-02 params: [0.34293333 1.069599   0.41823554]\n",
      "Epoch [2400/6000] Loss: 5.57e-02 params: [0.3502186 1.0819548 0.4317673]\n",
      "Epoch [2600/6000] Loss: 5.57e-02 params: [0.35755956 1.0958124  0.44690028]\n",
      "Epoch 02734: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [2800/6000] Loss: 5.56e-02 params: [0.3639135  1.1086922  0.46093494]\n",
      "Epoch [3000/6000] Loss: 5.56e-02 params: [0.36806744 1.1173133  0.47031394]\n",
      "Epoch [3200/6000] Loss: 5.56e-02 params: [0.3726183  1.1268796  0.48071608]\n",
      "Epoch [3400/6000] Loss: 5.55e-02 params: [0.37749615 1.1374809  0.49223277]\n",
      "Epoch [3600/6000] Loss: 5.55e-02 params: [0.38307527 1.1492454  0.504968  ]\n",
      "Epoch [3800/6000] Loss: 5.54e-02 params: [0.38916892 1.1622651  0.5190178 ]\n",
      "Epoch [4000/6000] Loss: 5.53e-02 params: [0.3955168 1.1766262 0.5344894]\n",
      "Epoch [4200/6000] Loss: 5.53e-02 params: [0.40238407 1.1924446  0.5514916 ]\n",
      "Epoch [4400/6000] Loss: 5.52e-02 params: [0.40982193 1.2098297  0.57013184]\n",
      "Epoch [4600/6000] Loss: 5.52e-02 params: [0.4178441  1.2288966  0.59051377]\n",
      "Epoch [4800/6000] Loss: 5.51e-02 params: [0.42639446 1.2497516  0.6127287 ]\n",
      "Epoch [5000/6000] Loss: 5.50e-02 params: [0.43553323 1.2724901  0.63685954]\n",
      "Epoch [5200/6000] Loss: 5.49e-02 params: [0.4453119  1.2971954  0.66296905]\n",
      "Epoch [5400/6000] Loss: 5.48e-02 params: [0.45581   1.3239274 0.6911018]\n",
      "Epoch [5600/6000] Loss: 5.47e-02 params: [0.46710756 1.3527206  0.7212788 ]\n",
      "Epoch 05780: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [5800/6000] Loss: 5.47e-02 params: [0.47867003 1.3820679  0.7519213 ]\n",
      "Epoch [6000/6000] Loss: 5.46e-02 params: [0.48527053 1.398501   0.76900977]\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# GEM 2N\n",
    "# H_1_1, cGEM=800\n",
    "\n",
    "known_param_4N = np.array([0.04754016, 1.06978193, 0.02534762, 0.00800557, 0.00394785, 800])\n",
    "file_G1, file_G2, file_P, file_D, file_G1_pred, file_G2_pred, file_P_pred, file_D_pred = drug_dose_param(pd.read_csv('csvs/H_1_1.csv'),known_param_4N,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c8f71e9-41c0-4958-8edd-0d126946827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg=0.48527053\n",
      "fm=1.398501\n",
      "fp=0.76900977\n"
     ]
    }
   ],
   "source": [
    "# PINN params\n",
    "loss_param = pd.read_csv('loss_param_1e.csv')\n",
    "fg = loss_param['fg']; fm = loss_param['fm']; fp = loss_param['fp']; \n",
    "fg_param = fg[len(fg)-1]; fm_param = fm[len(fm)-1]; fp_param = fp[len(fp)-1];\n",
    "\n",
    "print('fg='+str(fg_param))\n",
    "print('fm='+str(fm_param))\n",
    "print('fp='+str(fp_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e541ec-5e55-45bc-ab6e-ac7b18540a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "479e002c-03c8-4580-b293-292c70193f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FG Matrix:\n",
      "[[4.8942767e-02]\n",
      " [5.8532105e-06]\n",
      " [1.2257206e-06]\n",
      " [2.1821547e-01]\n",
      " [4.5898990e-01]\n",
      " [1.3935164e-01]\n",
      " [2.0507825e-06]\n",
      " [8.5874290e-03]\n",
      " [2.7072486e-01]\n",
      " [1.5408150e-06]\n",
      " [5.5031530e-06]\n",
      " [2.6773840e-05]\n",
      " [3.3405960e-05]\n",
      " [1.6821685e-05]\n",
      " [1.4426978e-05]\n",
      " [2.6213222e-05]\n",
      " [4.7238440e-05]\n",
      " [2.4882750e-05]\n",
      " [1.0655858e-06]\n",
      " [1.8087365e-05]\n",
      " [3.1229443e-05]\n",
      " [9.9825880e-05]\n",
      " [1.1365548e-05]\n",
      " [6.9107773e-07]\n",
      " [1.5959307e-09]\n",
      " [6.8328160e-10]\n",
      " [8.8011960e-10]\n",
      " [3.9276630e-09]\n",
      " [1.2076304e-03]\n",
      " [3.3243180e-01]\n",
      " [5.7977897e-01]\n",
      " [9.3644920e-01]\n",
      " [2.3262458e-01]\n",
      " [6.4359040e-02]\n",
      " [2.4624155e-01]\n",
      " [4.8527053e-01]]\n",
      "\n",
      "FM Matrix:\n",
      "[[3.3381486e-05]\n",
      " [2.8474462e-01]\n",
      " [6.8456426e-02]\n",
      " [1.4673647e-01]\n",
      " [6.6858166e-01]\n",
      " [6.7333984e-01]\n",
      " [2.3787631e-01]\n",
      " [2.0006588e-01]\n",
      " [8.6827725e-01]\n",
      " [9.0340980e-01]\n",
      " [8.2989380e-01]\n",
      " [8.9286816e-01]\n",
      " [1.0007280e+00]\n",
      " [9.9840050e-01]\n",
      " [9.9280643e-01]\n",
      " [1.0128875e+00]\n",
      " [1.0342630e+00]\n",
      " [1.0428274e+00]\n",
      " [1.0486866e+00]\n",
      " [1.0503994e+00]\n",
      " [1.1036727e+00]\n",
      " [1.1073649e+00]\n",
      " [1.1008618e+00]\n",
      " [1.1142932e+00]\n",
      " [1.1927582e+00]\n",
      " [1.2320665e+00]\n",
      " [1.2268244e+00]\n",
      " [1.1838260e+00]\n",
      " [1.1070297e+00]\n",
      " [1.5453370e+00]\n",
      " [1.5721480e+00]\n",
      " [1.8301921e+00]\n",
      " [6.6367507e-01]\n",
      " [6.2953514e-01]\n",
      " [4.8834476e-01]\n",
      " [1.3985010e+00]]\n",
      "\n",
      "FP Matrix:\n",
      "[[0.93288296]\n",
      " [1.0649403 ]\n",
      " [0.9525176 ]\n",
      " [1.4883664 ]\n",
      " [2.8191557 ]\n",
      " [2.0293932 ]\n",
      " [0.6392054 ]\n",
      " [1.0710055 ]\n",
      " [3.2862406 ]\n",
      " [2.5255768 ]\n",
      " [2.6088068 ]\n",
      " [2.7416446 ]\n",
      " [4.280553  ]\n",
      " [4.1156373 ]\n",
      " [4.2057157 ]\n",
      " [4.0853634 ]\n",
      " [5.092544  ]\n",
      " [6.0146546 ]\n",
      " [4.5776043 ]\n",
      " [4.193588  ]\n",
      " [4.218063  ]\n",
      " [6.2910576 ]\n",
      " [5.4660335 ]\n",
      " [4.4752164 ]\n",
      " [3.2976458 ]\n",
      " [3.1543045 ]\n",
      " [2.5080142 ]\n",
      " [3.958254  ]\n",
      " [1.9487678 ]\n",
      " [2.7516282 ]\n",
      " [2.6910331 ]\n",
      " [3.34505   ]\n",
      " [1.1221453 ]\n",
      " [1.0969592 ]\n",
      " [0.61221725]\n",
      " [0.76900977]]\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Path to the current notebook\n",
    "notebook_path = \"GEM_4n.ipynb\"  # Replace with the actual filename of your notebook\n",
    "\n",
    "# Lists to store the extracted values\n",
    "fg_values, fm_values, fp_values = [], [], []\n",
    "\n",
    "# Load the notebook\n",
    "with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Iterate over each cell in the notebook\n",
    "for cell in notebook.cells:\n",
    "    # Check if the cell contains output\n",
    "    if cell.cell_type == \"code\" and \"outputs\" in cell:\n",
    "        for output in cell.outputs:\n",
    "            # Ensure the output is text type and check for pattern\n",
    "            if output.output_type == \"stream\" and \"text\" in output:\n",
    "                output_text = output[\"text\"]\n",
    "\n",
    "                # Use regex to extract fg, fm, and fp values\n",
    "                fg_match = re.search(r\"fg=([\\d.eE+-]+)\", output_text)\n",
    "                fm_match = re.search(r\"fm=([\\d.eE+-]+)\", output_text)\n",
    "                fp_match = re.search(r\"fp=([\\d.eE+-]+)\", output_text)\n",
    "\n",
    "                # Append values if all three are found\n",
    "                if fg_match:\n",
    "                    fg_values.append(float(fg_match.group(1)))\n",
    "                if fm_match:\n",
    "                    fm_values.append(float(fm_match.group(1)))\n",
    "                if fp_match:\n",
    "                    fp_values.append(float(fp_match.group(1)))\n",
    "\n",
    "# Convert lists to separate matrices\n",
    "fg_matrix = np.array(fg_values).reshape(-1, 1)\n",
    "fm_matrix = np.array(fm_values).reshape(-1, 1)\n",
    "fp_matrix = np.array(fp_values).reshape(-1, 1)\n",
    "\n",
    "# Display the matrices\n",
    "print(\"FG Matrix:\")\n",
    "print(fg_matrix)\n",
    "print(\"\\nFM Matrix:\")\n",
    "print(fm_matrix)\n",
    "print(\"\\nFP Matrix:\")\n",
    "print(fp_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a261473e-70b6-49cf-8867-46bb4dd28666",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_matrix_2d = fg_matrix.reshape(9,4)\n",
    "fg_matrix_2d_T = fg_matrix_2d.T\n",
    "m_fg_matrix_2d_T = np.insert(fg_matrix_2d_T, 0, 0, axis=1)\n",
    "\n",
    "fm_matrix_2d = fm_matrix.reshape(9,4)\n",
    "fm_matrix_2d_T = fm_matrix_2d.T\n",
    "m_fm_matrix_2d_T = np.insert(fm_matrix_2d_T, 0, 0, axis=1)\n",
    "\n",
    "fp_matrix_2d = fp_matrix.reshape(9,4)\n",
    "fp_matrix_2d_T = fp_matrix_2d.T\n",
    "m_fp_matrix_2d_T = np.insert(fp_matrix_2d_T, 0, 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1235ca9-3e97-45e9-b9a1-f57dde84fa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 4.8942767e-02 4.5898990e-01 2.7072486e-01 3.3405960e-05\n",
      "  4.7238440e-05 3.1229443e-05 1.5959307e-09 1.2076304e-03 2.3262458e-01]\n",
      " [0.0000000e+00 5.8532105e-06 1.3935164e-01 1.5408150e-06 1.6821685e-05\n",
      "  2.4882750e-05 9.9825880e-05 6.8328160e-10 3.3243180e-01 6.4359040e-02]\n",
      " [0.0000000e+00 1.2257206e-06 2.0507825e-06 5.5031530e-06 1.4426978e-05\n",
      "  1.0655858e-06 1.1365548e-05 8.8011960e-10 5.7977897e-01 2.4624155e-01]\n",
      " [0.0000000e+00 2.1821547e-01 8.5874290e-03 2.6773840e-05 2.6213222e-05\n",
      "  1.8087365e-05 6.9107773e-07 3.9276630e-09 9.3644920e-01 4.8527053e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(m_fg_matrix_2d_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a25e074a-1c3a-4545-94eb-efc1375a57f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 3.3381486e-05 6.6858166e-01 8.6827725e-01 1.0007280e+00\n",
      "  1.0342630e+00 1.1036727e+00 1.1927582e+00 1.1070297e+00 6.6367507e-01]\n",
      " [0.0000000e+00 2.8474462e-01 6.7333984e-01 9.0340980e-01 9.9840050e-01\n",
      "  1.0428274e+00 1.1073649e+00 1.2320665e+00 1.5453370e+00 6.2953514e-01]\n",
      " [0.0000000e+00 6.8456426e-02 2.3787631e-01 8.2989380e-01 9.9280643e-01\n",
      "  1.0486866e+00 1.1008618e+00 1.2268244e+00 1.5721480e+00 4.8834476e-01]\n",
      " [0.0000000e+00 1.4673647e-01 2.0006588e-01 8.9286816e-01 1.0128875e+00\n",
      "  1.0503994e+00 1.1142932e+00 1.1838260e+00 1.8301921e+00 1.3985010e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(m_fm_matrix_2d_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "266f6f65-a773-45e0-8491-0c5c15545ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.93288296 2.8191557  3.2862406  4.280553   5.092544\n",
      "  4.218063   3.2976458  1.9487678  1.1221453 ]\n",
      " [0.         1.0649403  2.0293932  2.5255768  4.1156373  6.0146546\n",
      "  6.2910576  3.1543045  2.7516282  1.0969592 ]\n",
      " [0.         0.9525176  0.6392054  2.6088068  4.2057157  4.5776043\n",
      "  5.4660335  2.5080142  2.6910331  0.61221725]\n",
      " [0.         1.4883664  1.0710055  2.7416446  4.0853634  4.193588\n",
      "  4.4752164  3.958254   3.34505    0.76900977]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(m_fp_matrix_2d_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a7df3-ce05-4101-8d3e-c60e8bc385bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28f4672f-3bac-4ba6-ac41-eac4347877f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02447431010525\n",
      "0.10759644800000001\n",
      "1.00872895\n"
     ]
    }
   ],
   "source": [
    "# median fg 3\n",
    "fg_median_3 = np.median(m_fg_matrix_2d_T[:,1])\n",
    "print(fg_median_3)\n",
    "\n",
    "# median fm 3\n",
    "fm_median_3 = np.median(m_fm_matrix_2d_T[:,1])\n",
    "print(fm_median_3)\n",
    "\n",
    "# median fp 3\n",
    "fp_median_3 = np.median(m_fp_matrix_2d_T[:,1])\n",
    "print(fp_median_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f94e844-1b69-4ddd-af84-a2dd808e4eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1435836-16a2-4bee-9774-476aa9a0daeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
